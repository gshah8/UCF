{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gshah8/UCF/blob/master/Machine_Learning/HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KMwRoxS15IAB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# HW 1 \n",
        "\n",
        "This homework will get you up to speed with Python programming, numpy, matplotlib, Keras, gradients, partial derivatives, git, GitHub, Google's colaboratory etc. Have fun!\n",
        "\n",
        "For this homework, you will create neural networks with an input layer and an output layer without any hidden layers. The connections are dense: each input neuron is connected to each output neuron.\n",
        "\n",
        "Instructions for problems 1 and 2:\n",
        "- Load the training and test data using Keras, no validation set needed.\n",
        "- Train 10 classifiers that perform binary classification: *Is the input image the digit i or is it a digit different from i?* Each of the ten classifiers has an input layer consisting of 28 x 28 input neurons and an output layer consisting of a single output neuron.\n",
        "- Implement mini-batch stochastic gradient descent using only numpy, that is, you are not allowed to use TensorFlow/Keras for SGD.\n",
        "- Use ```argmax``` to determine the classifier with the strongest output and declare the corresponding digit as output.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "NLvuXGliw477",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "###Loading data for Problems 1-4"
      ]
    },
    {
      "metadata": {
        "id": "VAz7FzJqxSul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()\n",
        "#print(train_labels_original.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t-MVyXrIq0De",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Functions to be used throughout the homework"
      ]
    },
    {
      "metadata": {
        "id": "oukl0-J44ebU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data_bias():\n",
        "  \n",
        "  #for reshaping and normalizing train and test images\n",
        "  m = 60000\n",
        "  n = 10000\n",
        "  image_size = 28*28\n",
        "  train_images = train_images_original.reshape((m, image_size))\n",
        "  train_images = train_images.astype('float32') / 255\n",
        "  test_images = test_images_original.reshape((n, image_size))\n",
        "  test_images = test_images.astype('float32') / 255\n",
        "  \n",
        "  #for adding bias to train and test images\n",
        "  train_images_b = np.c_[np.ones((m, 1)), train_images]\n",
        "  test_images_b = np.c_[np.ones((n, 1)), test_images]\n",
        "  \n",
        "  #one-hot encoding for labels\n",
        "  for i in range(m):\n",
        "    train_labels[i][train_labels_original[i]] = 1\n",
        "  for i in range(n):\n",
        "    test_labels[i][test_labels_original[i]] = 1\n",
        "  \n",
        "  return train_images_b, train_labels,test_images_b, test_labels\n",
        "\n",
        "\n",
        "def sigmoid(z):\n",
        "  ans = 1/(1+np.exp(-z))\n",
        "  return ans\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "spr8mEbwxEIf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 1\n",
        "Use logistic regression with mean squared error loss."
      ]
    },
    {
      "metadata": {
        "id": "4XwQkWl55lCZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images_b, train_labels,test_images_b, test_labels = load_data_bias()\n",
        "#print(train_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xAG0QHmp96qh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#initializing weight and big_weight for 10 classifiers\n",
        "\n",
        "np.random.seed(42)\n",
        "initial_weight=np.zeros((image_size+1,1))\n",
        "weight_10=np.zeros((image_size+1,10))\n",
        "#weight_10.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bmCLK_zjCxcY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "lr = 0.001\n",
        "batch_size = 64\n",
        "classifiers = 10\n",
        "\n",
        "for j in range(classifiers):\n",
        "  weight = initial_weight\n",
        "  for epoch in range(epochs):\n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    train_images_b_shuffled = train_images_b[shuffled_indices]\n",
        "    train_labels_shuffled = train_labels[:,j][shuffled_indices]   \n",
        "    for i in range(0,m,batch_size):\n",
        "      x_i = train_images_b_shuffled[i:i+batch_size]\n",
        "      y_i = train_labels_shuffled[i:i+batch_size]\n",
        "      y_i = y_i.reshape((y_i.size,1))\n",
        "      z = x_i.dot(weight)\n",
        "      a = sigmoid(z)\n",
        "      dlda = a-y_i\n",
        "      dadz=a*(1-a)\n",
        "      dzdw = x_i\n",
        "      gradient = 1/batch_size * x_i.T.dot(dadz*dlda)\n",
        "      weight = weight - lr * gradient\n",
        "  weight_10[:,j] = weight.reshape(785,)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p_dtXNOmnubO",
        "colab_type": "code",
        "outputId": "145d81d5-1ed9-4e61-cc88-4a60b03df782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "weight_10.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(785, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "KvaQES5rFrbm",
        "colab_type": "code",
        "outputId": "b0e483e2-80e5-4b03-a3bb-55e45ebc0ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "z_pred = train_images_b[2].dot(weight_10)\n",
        "a_pred = sigmoid(z_pred)\n",
        "print(a_pred)\n",
        "print(\"Prediction=\",np.argmax(a_pred))\n",
        "print(\"true_label = \" , train_labels_original[2])\n",
        "#train_acc = train_labels - y_predict"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.19345586 0.07743006 0.27157083 0.28127237 0.61025647 0.21428655\n",
            " 0.25739437 0.18951868 0.22155289 0.33045379]\n",
            "Prediction= 4\n",
            "true_label =  4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qx8nkGTZomIX",
        "colab_type": "code",
        "outputId": "60e1403b-79af-4d6d-b8fc-615e727302d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "z_pred_test = test_images_b.dot(weight_10)\n",
        "a_pred_test = sigmoid(z_pred_test)\n",
        "\n",
        "a_pred_test_numb=np.argmax(a_pred_test,axis=1)\n",
        "a_pred_test_numb.shape\n",
        "\n",
        "np.sum(a_pred_test_numb==test_labels_original)/test_labels_original.shape[0]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8037"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "metadata": {
        "id": "bN-mUe3l9zOH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 2\n",
        "Use logistic regression with binary cross entropy loss."
      ]
    },
    {
      "metadata": {
        "id": "4q9XBuNV99LW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images_b, train_labels,test_images_b, test_labels = load_data_bias()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "itV4R78M71TF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "initial_weight=np.zeros((image_size+1,1))\n",
        "weight_10=np.zeros((image_size+1,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mEJA8tTk75OG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "lr = 0.001\n",
        "batch_size = 64\n",
        "classifiers = 10\n",
        "\n",
        "for j in range(classifiers):\n",
        "  weight = initial_weight\n",
        "  for epoch in range(epochs):\n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    train_images_b_shuffled = train_images_b[shuffled_indices]\n",
        "    train_labels_shuffled = train_labels[:,j][shuffled_indices]   \n",
        "    for i in range(0,m,batch_size):\n",
        "      x_i = train_images_b_shuffled[i:i+batch_size]\n",
        "      y_i = train_labels_shuffled[i:i+batch_size]\n",
        "      y_i = y_i.reshape((y_i.size,1))\n",
        "      z = x_i.dot(weight)\n",
        "      a = sigmoid(z)\n",
        "      dlda = a-y_i\n",
        "      dadz=a*(1-a)\n",
        "      dzdw = x_i\n",
        "      gradient = 1/batch_size * x_i.T.dot(dadz*dlda)\n",
        "      weight = weight - lr * gradient\n",
        "  weight_10[:,j] = weight.reshape(785,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PfaoTj-_8DY-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z_pred = train_images_b[2].dot(weight_10)\n",
        "a_pred = sigmoid(z_pred)\n",
        "print(a_pred)\n",
        "print(\"Prediction=\",np.argmax(a_pred))\n",
        "print(\"true_label = \" , train_labels_original[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-POCx5xi8EH-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z_pred_test = test_images_b.dot(weight_10)\n",
        "a_pred_test = sigmoid(z_pred_test)\n",
        "\n",
        "a_pred_test_numb=np.argmax(a_pred_test,axis=1)\n",
        "a_pred_test_numb.shape\n",
        "\n",
        "np.sum(a_pred_test_numb==test_labels_original)/test_labels_original.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ctzMUL6-MZP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 3\n",
        "- Load the training and test data using Keras, no validation set needed.\n",
        "- Create network with an input layer consisting of 28 x 28 input neurons and an output layer consisting of 10 output neurons.\n",
        "- Use softmax and categorical cross entropy loss.\n",
        "- Implement mini-batch stochastic gradient descent using only numpy, that is, you are not allowed to use TensorFlow/Keras for SGD."
      ]
    },
    {
      "metadata": {
        "id": "6u5AvT1V-PX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "44371e2e-0cef-458f-fd08-07e5b5f34f66"
      },
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Q_ZrNeDaFvA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for reshaping and normalizing train and test images\n",
        "m = 60000\n",
        "n = 10000\n",
        "image_size = 28*28\n",
        "train_images = train_images_original.reshape((m, image_size))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images_original.reshape((n, image_size))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GvfhUqR-aR0T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for adding bias to train and test images\n",
        "train_images_b = np.c_[np.ones((m, 1)), train_images]\n",
        "test_images_b = np.c_[np.ones((n, 1)), test_images]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UI3Vz40U6D-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91b3c4f1-b693-4398-854e-567dda2aad86"
      },
      "cell_type": "code",
      "source": [
        "#for adding bias to train and test labels. Doing something like one-hot encoding for labels\n",
        "train_labels = np.zeros((m,10))\n",
        "test_labels = np.zeros((n,10))\n",
        "\n",
        "for i in range(m):\n",
        "  train_labels[i][train_labels_original[i]] = 1\n",
        "  \n",
        "for i in range(n):\n",
        "  test_labels[i][test_labels_original[i]] = 1\n",
        "test_labels.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "uw_DcCKeatQK",
        "colab_type": "code",
        "outputId": "d23d6a52-9da5-4b27-cd51-9a7076dc51cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "#for setting weight\n",
        "\n",
        "np.random.seed(42)\n",
        "#initial_weight = np.random.randn(image_size+1,10)\n",
        "initial_weight = np.zeros((image_size+1,10))\n",
        "weight_path_mgd = []\n",
        "batch_size = 40\n",
        "initial_weight"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "AXhMx7kLVYYw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def softmax(z):\n",
        "  z_exp=np.exp(z)\n",
        "  #rint(z_exp.shape)\n",
        "  #rint(z_exp)\n",
        "  total=np.sum(z_exp,axis=1)\n",
        "  #rint(total.shape)\n",
        "  #rint(total)\n",
        "  return z_exp/total.reshape(z_exp.shape[0],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mwsg2KRJPS3E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(z):\n",
        "  z_exp=np.exp(z)\n",
        "  total=np.sum(z_exp)\n",
        "  return z_exp/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Owj522VEOwHZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#this is for linear regression. Change it for logistic regression\n",
        "\n",
        "epochs = 20\n",
        "lr = 0.001\n",
        "weight = initial_weight\n",
        "\n",
        "weight_path_mgd.append(weight)\n",
        "for epoch in range(epochs):\n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    train_images_b_shuffled = train_images_b[shuffled_indices]\n",
        "    train_labels_shuffled = train_labels[shuffled_indices]\n",
        "    for i in range(0, m, batch_size):\n",
        "      train_images_b_i = train_images_b_shuffled[i:i+batch_size]\n",
        "      train_labels_b_i = train_labels_shuffled[i:i+batch_size]\n",
        "      z = train_images_b_i.dot(weight)\n",
        "\n",
        "      #apply activation - softmax\n",
        "      #z_exp = np.exp(z)\n",
        "      #z_exp_sum = z_exp.sum(axis=1)\n",
        "      #a = np.zeros((batch_size,10))\n",
        "      #for j in range(len(z)):\n",
        "      #  a[j] = z_exp[j] / z_exp_sum[j]\n",
        "      a = softmax(z)\n",
        "      \n",
        "      \n",
        "      #now loss - categorical cross entropy\n",
        "      #loss = np.zeros((batch_size,1))\n",
        "      #for j in range(len(z)):\n",
        "      #  loss[j] = -1*train_labels[j].dot(np.log(a[j].T))\n",
        "      \n",
        "      #gradient descent - msgd\n",
        "      #do we use the loss from above or directly use the gradient???\n",
        "      #How to use loss cce to calculate gradient\n",
        "      gradient = 1/batch_size * train_images_b_i.T.dot(a - train_labels_b_i)\n",
        "      weight = weight - lr * gradient\n",
        "      weight_path_mgd.append(weight) \n",
        "        \n",
        "        \n",
        "      #break\n",
        "    #break\n",
        "    \n",
        "        #a = np.zeros((10,1))\n",
        "        #for j in range(len(z)):\n",
        "        #  a[j] = np.exp(z)\n",
        "\n",
        "#print(z_exp_sum)\n",
        "#print(z[0][0])\n",
        "#print(z_exp[0][0])\n",
        "#print(len(z))\n",
        "#print(a.shape)\n",
        "\n",
        "#sum_arr = np.zeros((64,1))\n",
        "#sum_arr = a.sum(axis=1)\n",
        "#print(sum_arr)\n",
        "#print(loss)\n",
        "\n",
        "        #gradient = 2/batch_size * xi.T.dot(xi.dot(weight) - yi)\n",
        "        #weight = weight - lr * gradient\n",
        "        #weight_path_mgd.append(weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SUsY1uutaRuQ",
        "colab_type": "code",
        "outputId": "041ff8ad-6d3f-4ae1-fa44-7d0542135869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "cell_type": "code",
      "source": [
        "weight"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.07994857,  0.16427201, -0.03615793, ...,  0.10580816,\n",
              "        -0.25043564, -0.03665279],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "72LAURd9cK0s",
        "colab_type": "code",
        "outputId": "24baada4-33d8-4cd1-cdbc-84e59ae1fa87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "#For Training and Testing Accuracy\n",
        "\n",
        "mt=test_labels_original.shape[0]\n",
        "predicted_labels_test_raw=test(test_images_b.dot(weight))  \n",
        "print(predicted_labels_test_raw.shape)\n",
        "predicted_labels_test=np.argmax(predicted_labels_test_raw,axis=1)\n",
        "print(predicted_labels_test.shape)\n",
        "print(test_labels_original.shape)\n",
        "predicted_labels_test = predicted_labels_test.astype('uint8')\n",
        "test_labels_original=test_labels_original.astype('uint8')\n",
        "\n",
        "wrong_indices_test = [i for i in range(mt) if predicted_labels_test[i] != test_labels_original[i]]\n",
        "# The quantity below is equal to the test accuracy reported by the network fit method.\n",
        "acc_test=1.0 - len(wrong_indices_test) / mt\n",
        "print(\"Test acc= \",acc_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10)\n",
            "(10000,)\n",
            "(10000,)\n",
            "Test acc=  0.8929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jM98Wwzi-QJG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 4\n",
        "Reimplement the network from Problem 3 entirely in Keras."
      ]
    },
    {
      "metadata": {
        "id": "g3TYeh_a-S2x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W9ZAQlsWL7d_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images = train_images_original.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images_original.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "#train_images_original.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "domURlv2NjFu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels_original)\n",
        "test_labels = to_categorical(test_labels_original)\n",
        "#test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8johAcgDOBlc",
        "colab_type": "code",
        "outputId": "9e7869e6-ef60-4a18-f261-35feeda3633f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "#network.add(layers.Dense(28*28, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax',input_shape=(28 * 28,)))\n",
        "network.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HZT0zpBQOtqM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network.compile(optimizer='sgd',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lT8y2kRrPaC8",
        "colab_type": "code",
        "outputId": "059f141b-1c52-493f-c56b-3ad8706fc806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "history = network.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=128, \n",
        "                      validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 1.2842 - acc: 0.6944 - val_loss: 0.8124 - val_acc: 0.8321\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.7151 - acc: 0.8415 - val_loss: 0.6076 - val_acc: 0.8631\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.5864 - acc: 0.8595 - val_loss: 0.5265 - val_acc: 0.8745\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.5250 - acc: 0.8680 - val_loss: 0.4807 - val_acc: 0.8807\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.4875 - acc: 0.8741 - val_loss: 0.4510 - val_acc: 0.8852\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.4618 - acc: 0.8786 - val_loss: 0.4296 - val_acc: 0.8884\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.4427 - acc: 0.8829 - val_loss: 0.4137 - val_acc: 0.8933\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.4278 - acc: 0.8860 - val_loss: 0.4008 - val_acc: 0.8948\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.4158 - acc: 0.8885 - val_loss: 0.3904 - val_acc: 0.8977\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.4059 - acc: 0.8905 - val_loss: 0.3815 - val_acc: 0.8985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bCzA_kZ-R1GO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "test_loss_values = history_dict['val_loss']\n",
        "epochs_range = range(1, epochs + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4wF0qIOR5HF",
        "colab_type": "code",
        "outputId": "4d4450be-4552-451f-bd96-bb552e47d930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "plt.plot(epochs_range, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, test_loss_values, 'ro', label='Test loss')\n",
        "plt.title('Training and test loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rDEC8H3vdwL-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Add a plot for training and test loss"
      ]
    },
    {
      "metadata": {
        "id": "r9ZsMF6iVBmv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHSfWEWJ-TpS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 5\n",
        "Extend the network from Problem 4 by adding new features.\n",
        "- Round the grey values of the images to 1 and 0 so you obtain black and white images. Add as an additional feature the number of white regions. For instance, a typical 0 has 2 white regions and 8 has 3. Use the following neighborhoods for pixels:\n",
        "\n",
        "```\n",
        "pixel x,y (indicated by .) is connected to its neighbors (indicated by o):\n",
        "\n",
        " o\n",
        "o.o  \n",
        " o\n",
        " \n",
        "ooo\n",
        "o.o\n",
        "ooo\n",
        "```\n",
        "- Consider the width.\n",
        "- Consider the height.\n",
        "- Come up with other features.\n",
        "\n",
        "You should normalize your new features so that they are at the same scale as the pixel values (between 0 and 1)."
      ]
    },
    {
      "metadata": {
        "id": "IM5yz84l-bAf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}