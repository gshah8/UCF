{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gshah8/UCF/blob/master/Machine_Learning/HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KMwRoxS15IAB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# HW 1 \n",
        "\n",
        "This homework will get you up to speed with Python programming, numpy, matplotlib, Keras, gradients, partial derivatives, git, GitHub, Google's colaboratory etc. Have fun!\n",
        "\n",
        "For this homework, you will create neural networks with an input layer and an output layer without any hidden layers. The connections are dense: each input neuron is connected to each output neuron.\n",
        "\n",
        "Instructions for problems 1 and 2:\n",
        "- Load the training and test data using Keras, no validation set needed.\n",
        "- Train 10 classifiers that perform binary classification: *Is the input image the digit i or is it a digit different from i?* Each of the ten classifiers has an input layer consisting of 28 x 28 input neurons and an output layer consisting of a single output neuron.\n",
        "- Implement mini-batch stochastic gradient descent using only numpy, that is, you are not allowed to use TensorFlow/Keras for SGD.\n",
        "- Use ```argmax``` to determine the classifier with the strongest output and declare the corresponding digit as output.\n",
        "\n",
        "## Problem 1\n",
        "Use logistic regression with mean squared error loss."
      ]
    },
    {
      "metadata": {
        "id": "4XwQkWl55lCZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bN-mUe3l9zOH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 2\n",
        "Use logistic regression with binary cross entropy loss."
      ]
    },
    {
      "metadata": {
        "id": "4q9XBuNV99LW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ctzMUL6-MZP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 3\n",
        "- Load the training and test data using Keras, no validation set needed.\n",
        "- Create network with an input layer consisting of 28 x 28 input neurons and an output layer consisting of 10 output neurons.\n",
        "- Use softmax and categorical cross entropy loss.\n",
        "- Implement mini-batch stochastic gradient descent using only numpy, that is, you are not allowed to use TensorFlow/Keras for SGD."
      ]
    },
    {
      "metadata": {
        "id": "6u5AvT1V-PX7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load data\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Q_ZrNeDaFvA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for images\n",
        "m = 60000\n",
        "n = 10000\n",
        "image_size = 28*28\n",
        "train_images = train_images_original.reshape((m, image_size))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images_original.reshape((n, image_size))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GvfhUqR-aR0T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for images\n",
        "train_images_b = np.c_[np.ones((m, 1)), train_images]\n",
        "#train_images_b.shape\n",
        "test_images_b = np.c_[np.ones((n, 1)), test_images]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UI3Vz40U6D-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for labels. Doing something like one-hot encoding for labels\n",
        "train_labels = np.zeros((m,10))\n",
        "test_labels = np.zeros((n,10))\n",
        "\n",
        "for i in range(m):\n",
        "  train_labels[i][train_labels_original[i]] = 1\n",
        "  \n",
        "for i in range(n):\n",
        "  test_labels[i][test_labels_original[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uw_DcCKeatQK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for setting weight\n",
        "\n",
        "np.random.seed(42)\n",
        "weight = np.random.randn(image_size+1,1)\n",
        "weight_path_mgd = []\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Owj522VEOwHZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#this is for linear regression. Change it for logistic regression\n",
        "\n",
        "epochs = 10\n",
        "lr = 0.01\n",
        "\n",
        "weight_path_mgd.append(weight)\n",
        "for epoch in range(epochs):\n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_b_shuffled = X_b[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "    for i in range(0, m, batch_size):\n",
        "        xi = X_b_shuffled[i:i+batch_size]\n",
        "        yi = y_shuffled[i:i+batch_size]\n",
        "        gradient = 2/batch_size * xi.T.dot(xi.dot(weight) - yi)\n",
        "        weight = weight - lr * gradient\n",
        "        weight_path_mgd.append(weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "72LAURd9cK0s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Loss "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jM98Wwzi-QJG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 4\n",
        "Reimplement the network from Problem 3 entirely in Keras."
      ]
    },
    {
      "metadata": {
        "id": "g3TYeh_a-S2x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W9ZAQlsWL7d_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images = train_images_original.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images_original.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "#train_images_original.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "domURlv2NjFu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels_original)\n",
        "test_labels = to_categorical(test_labels_original)\n",
        "#test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8johAcgDOBlc",
        "colab_type": "code",
        "outputId": "910b312a-1d03-4c48-8533-49096ad67763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(28*28, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "network.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 623,290\n",
            "Trainable params: 623,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HZT0zpBQOtqM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network.compile(optimizer='sgd',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lT8y2kRrPaC8",
        "colab_type": "code",
        "outputId": "1be1cfde-8cde-4594-f0e8-7161fa3283ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "history = network.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=128, \n",
        "                      validation_data=(test_images, test_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 1.0802 - acc: 0.7649 - val_loss: 0.5847 - val_acc: 0.8721\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.5120 - acc: 0.8757 - val_loss: 0.4235 - val_acc: 0.8937\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.4133 - acc: 0.8913 - val_loss: 0.3665 - val_acc: 0.9042\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.3685 - acc: 0.9001 - val_loss: 0.3339 - val_acc: 0.9108\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.3409 - acc: 0.9068 - val_loss: 0.3136 - val_acc: 0.9148\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.3212 - acc: 0.9115 - val_loss: 0.2977 - val_acc: 0.9185\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.3059 - acc: 0.9157 - val_loss: 0.2852 - val_acc: 0.9206\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.2930 - acc: 0.9189 - val_loss: 0.2747 - val_acc: 0.9245\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 93us/step - loss: 0.2823 - acc: 0.9216 - val_loss: 0.2658 - val_acc: 0.9270\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 94us/step - loss: 0.2725 - acc: 0.9245 - val_loss: 0.2574 - val_acc: 0.9285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bCzA_kZ-R1GO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "test_loss_values = history_dict['val_loss']\n",
        "epochs_range = range(1, epochs + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4wF0qIOR5HF",
        "colab_type": "code",
        "outputId": "a8ee6441-dbc7-4e38-d2c0-1373742a4cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(epochs_range, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, test_loss_values, 'ro', label='Test loss')\n",
        "plt.title('Training and test loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4rEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "r9ZsMF6iVBmv",
        "colab_type": "code",
        "outputId": "59ba03f8-3319-4151-c5c8-44dfe1f7bec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 65us/step\n",
            "Test accuracy: 0.9285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cHSfWEWJ-TpS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 5\n",
        "Extend the network from Problem 4 by adding new features.\n",
        "- Round the grey values of the images to 1 and 0 so you obtain black and white images. Add as an additional feature the number of white regions. For instance, a typical 0 has 2 white regions and 8 has 3. Use the following neighborhoods for pixels:\n",
        "\n",
        "```\n",
        "pixel x,y (indicated by .) is connected to its neighbors (indicated by o):\n",
        "\n",
        " o\n",
        "o.o  \n",
        " o\n",
        " \n",
        "ooo\n",
        "o.o\n",
        "ooo\n",
        "```\n",
        "- Consider the width.\n",
        "- Consider the height.\n",
        "- Come up with other features.\n",
        "\n",
        "You should normalize your new features so that they are at the same scale as the pixel values (between 0 and 1)."
      ]
    },
    {
      "metadata": {
        "id": "IM5yz84l-bAf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}