{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gshah8/UCF/blob/master/Machine_Learning/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5vSpuR2h9REm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# HW 2\n",
        "\n",
        "The goal of this homework is to create a convolutional neural network for the CIFAR10 data set. \n",
        "See [this colab notebook](https://colab.research.google.com/drive/1LZZviWOzvchcXRdZi2IBx3KOpQOzLalf) how to load the CIFAR data in Keras.\n",
        "\n",
        "You should not use any pretrained convnets that come with Keras. You have to create and train your own convnets with Keras from scratch.\n",
        "\n",
        "## Simple hold-out validation\n",
        "\n",
        "Make sure that the data is divided into: \n",
        "\n",
        "- training set (80%)\n",
        "- validation set (20%)\n",
        "- test set. \n",
        "\n",
        "Use the training set to train your neural networks. Evaluate their performance on the validation data set. \n",
        "\n",
        "After trying several different architectures, choose the one that performs\n",
        "best of the validation set. Try at least four different architectures by using data augmentation, using dropout, varying the number of layers, the number of filters, etc.\n",
        "\n",
        "Train this final architecture on the data from the training set and validation set and evaluate its performance on \n",
        "the test set.\n",
        "\n",
        "## k-fold validation\n",
        "\n",
        "Reevaluate your best architecture using k-fold validation with k=5, that is, the size of the validation fold is 20%. Does the accuracy/loss obtain by k-fold validation differ from the accuracy/loss obtain by simple hold-out validation."
      ]
    },
    {
      "metadata": {
        "id": "tGt5GSXu_g9t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the CIFAR10 data set\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GaciVEq0_dts",
        "colab_type": "code",
        "outputId": "db2c61cf-6fa9-4e58-91cd-b976c92746a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 175s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-AYEf3umAHQm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Explore the format of the CIFAR10 data set"
      ]
    },
    {
      "metadata": {
        "id": "p1hNMiPtAIsN",
        "colab_type": "code",
        "outputId": "74d4751c-eb58-42a0-a368-5ee7467fced2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "J6KJNpLlAtLb",
        "colab_type": "code",
        "outputId": "73b304fe-35d4-4992-94f9-3230c256425d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_images.ndim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "8_SDVSLrAx1L",
        "colab_type": "code",
        "outputId": "bb6ec80b-5894-44aa-a97f-04e3815cffa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "14iRg_dJA0Iv",
        "colab_type": "code",
        "outputId": "36fdacd7-c8fc-4c1d-c3c2-f1d9368a87b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_labels.ndim"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "Mqbp1flDTvGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Simple Hold Validation for the models below"
      ]
    },
    {
      "metadata": {
        "id": "ghUwL-nmUZx8",
        "colab_type": "code",
        "outputId": "73707157-a3b2-4712-aa54-8bfefb2fed7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#divide training data into training and validation data\n",
        "rand_idx = np.random.permutation(len(train_images))\n",
        "val_idx = rand_idx[0:10000]\n",
        "train_idx = rand_idx[10000:]\n",
        "\n",
        "train_images_new, train_labels_new = train_images[train_idx] , train_labels[train_idx]\n",
        "val_images, val_labels = train_images[val_idx] , train_labels[val_idx]\n",
        "\n",
        "print(train_labels_new[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FbOE5y_-EzOV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Normalize train, validation and test data\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "w4u6Vq_KE6Oe",
        "colab_type": "code",
        "outputId": "367eb755-9a7e-4dde-896f-dd7905665db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#normalize\n",
        "train_images_norm = (train_images_new/255).astype('float32')\n",
        "val_images_norm = (val_images/255).astype('float32')\n",
        "test_images_norm = (test_images/255).astype('float32')\n",
        "\n",
        "#one-hot encoding\n",
        "train_labels_norm = to_categorical(train_labels_new)\n",
        "val_labels_norm = to_categorical(val_labels)\n",
        "test_labels_norm = to_categorical(test_labels)\n",
        "\n",
        "print(train_labels_norm[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9vynlXErFcqO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Build a basic model (without regularization and data augmentation)"
      ]
    },
    {
      "metadata": {
        "id": "4d7o1oJLFeqm",
        "colab_type": "code",
        "outputId": "b981b1a1-f648-4f70-fd3b-4525327e877c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "# set up the layers\n",
        "\n",
        "model = models.Sequential()\n",
        "#conv layers   \n",
        "#1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#3\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 122,570\n",
            "Trainable params: 122,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UY6Yl69XH4b4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ULo_pCDVIJd_",
        "colab_type": "code",
        "outputId": "e2abe6df-5a6e-485a-b9b0-2ff6a8607afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "history = model.fit(train_images_norm, \n",
        "                      train_labels_norm, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=64, \n",
        "                      validation_data=(val_images_norm, val_labels_norm))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "40000/40000 [==============================] - 13s 316us/step - loss: 1.5815 - acc: 0.4276 - val_loss: 1.3115 - val_acc: 0.5238\n",
            "Epoch 2/20\n",
            "40000/40000 [==============================] - 8s 195us/step - loss: 1.1898 - acc: 0.5784 - val_loss: 1.0927 - val_acc: 0.6217\n",
            "Epoch 3/20\n",
            "40000/40000 [==============================] - 8s 196us/step - loss: 1.0071 - acc: 0.6487 - val_loss: 1.0335 - val_acc: 0.6364\n",
            "Epoch 4/20\n",
            "40000/40000 [==============================] - 8s 197us/step - loss: 0.9048 - acc: 0.6846 - val_loss: 0.9386 - val_acc: 0.6726\n",
            "Epoch 5/20\n",
            "40000/40000 [==============================] - 8s 195us/step - loss: 0.8213 - acc: 0.7162 - val_loss: 0.8847 - val_acc: 0.6927\n",
            "Epoch 6/20\n",
            "40000/40000 [==============================] - 8s 196us/step - loss: 0.7595 - acc: 0.7376 - val_loss: 0.8928 - val_acc: 0.6895\n",
            "Epoch 7/20\n",
            "40000/40000 [==============================] - 8s 197us/step - loss: 0.7037 - acc: 0.7551 - val_loss: 0.8464 - val_acc: 0.7121\n",
            "Epoch 8/20\n",
            "40000/40000 [==============================] - 8s 195us/step - loss: 0.6587 - acc: 0.7690 - val_loss: 0.8349 - val_acc: 0.7165\n",
            "Epoch 9/20\n",
            "40000/40000 [==============================] - 8s 195us/step - loss: 0.6109 - acc: 0.7893 - val_loss: 0.8328 - val_acc: 0.7182\n",
            "Epoch 10/20\n",
            "40000/40000 [==============================] - 8s 195us/step - loss: 0.5675 - acc: 0.8014 - val_loss: 0.9025 - val_acc: 0.7064\n",
            "Epoch 11/20\n",
            "40000/40000 [==============================] - 8s 199us/step - loss: 0.5298 - acc: 0.8167 - val_loss: 0.8964 - val_acc: 0.7080\n",
            "Epoch 12/20\n",
            "40000/40000 [==============================] - 8s 197us/step - loss: 0.4897 - acc: 0.8287 - val_loss: 0.9070 - val_acc: 0.7080\n",
            "Epoch 13/20\n",
            "40000/40000 [==============================] - 8s 197us/step - loss: 0.4580 - acc: 0.8421 - val_loss: 0.8864 - val_acc: 0.7272\n",
            "Epoch 14/20\n",
            "40000/40000 [==============================] - 8s 196us/step - loss: 0.4202 - acc: 0.8521 - val_loss: 0.9358 - val_acc: 0.7172\n",
            "Epoch 15/20\n",
            "40000/40000 [==============================] - 8s 196us/step - loss: 0.3933 - acc: 0.8609 - val_loss: 0.9868 - val_acc: 0.7175\n",
            "Epoch 16/20\n",
            "40000/40000 [==============================] - 8s 195us/step - loss: 0.3600 - acc: 0.8720 - val_loss: 0.9909 - val_acc: 0.7180\n",
            "Epoch 17/20\n",
            "40000/40000 [==============================] - 8s 194us/step - loss: 0.3335 - acc: 0.8821 - val_loss: 1.1051 - val_acc: 0.7084\n",
            "Epoch 18/20\n",
            "40000/40000 [==============================] - 8s 193us/step - loss: 0.3107 - acc: 0.8899 - val_loss: 1.0684 - val_acc: 0.7183\n",
            "Epoch 19/20\n",
            "40000/40000 [==============================] - 8s 194us/step - loss: 0.2836 - acc: 0.9001 - val_loss: 1.1754 - val_acc: 0.7096\n",
            "Epoch 20/20\n",
            "40000/40000 [==============================] - 8s 193us/step - loss: 0.2549 - acc: 0.9093 - val_loss: 1.1712 - val_acc: 0.7149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B-dIySPtN-Gj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can observe that the model is clearly overfitted since the training accuracy is increasing as we increase the number of epochs but the validation accuracy is not increasing.\n",
        "\n",
        "Now, we will try to improve the model by using the four following architectures:\n",
        "1. Add another convolutional layer\n",
        "2. Data Augmentation\n",
        "3. Regularization - Dropout\n",
        "4. Regularization - Batch Normalization\n",
        "5. Strides\n",
        "\n",
        "We will add the above mentioned architectures one by one and observe the training and validation accuracy.\n",
        "In the end, as a final check, we will run the model for test data."
      ]
    },
    {
      "metadata": {
        "id": "kHsI-SikNtfQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Add another convolutional layer"
      ]
    },
    {
      "metadata": {
        "id": "pTnpHLaERnpt",
        "colab_type": "code",
        "outputId": "f5936f02-8525-49c8-8c76-56b7dd773bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "cell_type": "code",
      "source": [
        "# set up the layers\n",
        "\n",
        "model = models.Sequential()\n",
        "#conv layers   \n",
        "#1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#3\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu',padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#4\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 307,786\n",
            "Trainable params: 307,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wEx0Pl9CQlCE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T7RPGQ7ZQqcV",
        "colab_type": "code",
        "outputId": "52067a42-4532-46b5-c048-20d03aa362f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1394
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "history = model.fit(train_images_norm, \n",
        "                      train_labels_norm, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=64, \n",
        "                      validation_data=(val_images_norm, val_labels_norm))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "40000/40000 [==============================] - 13s 320us/step - loss: 1.5315 - acc: 0.4386 - val_loss: 1.1855 - val_acc: 0.5765\n",
            "Epoch 2/40\n",
            "40000/40000 [==============================] - 12s 307us/step - loss: 1.0776 - acc: 0.6172 - val_loss: 0.9951 - val_acc: 0.6434\n",
            "Epoch 3/40\n",
            "40000/40000 [==============================] - 12s 307us/step - loss: 0.8594 - acc: 0.6993 - val_loss: 0.8426 - val_acc: 0.7057\n",
            "Epoch 4/40\n",
            "40000/40000 [==============================] - 12s 307us/step - loss: 0.7226 - acc: 0.7481 - val_loss: 0.8352 - val_acc: 0.7143\n",
            "Epoch 5/40\n",
            "40000/40000 [==============================] - 12s 304us/step - loss: 0.6211 - acc: 0.7825 - val_loss: 0.7482 - val_acc: 0.7410\n",
            "Epoch 6/40\n",
            "40000/40000 [==============================] - 12s 302us/step - loss: 0.5231 - acc: 0.8160 - val_loss: 0.7746 - val_acc: 0.7406\n",
            "Epoch 7/40\n",
            "40000/40000 [==============================] - 12s 304us/step - loss: 0.4426 - acc: 0.8442 - val_loss: 0.7628 - val_acc: 0.7428\n",
            "Epoch 8/40\n",
            "40000/40000 [==============================] - 12s 305us/step - loss: 0.3656 - acc: 0.8723 - val_loss: 0.8258 - val_acc: 0.7451\n",
            "Epoch 9/40\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.2990 - acc: 0.8951 - val_loss: 0.8624 - val_acc: 0.7444\n",
            "Epoch 10/40\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.2449 - acc: 0.9131 - val_loss: 0.9339 - val_acc: 0.7481\n",
            "Epoch 11/40\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.2040 - acc: 0.9266 - val_loss: 1.0148 - val_acc: 0.7394\n",
            "Epoch 12/40\n",
            "40000/40000 [==============================] - 12s 300us/step - loss: 0.1731 - acc: 0.9391 - val_loss: 1.1209 - val_acc: 0.7396\n",
            "Epoch 13/40\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.1469 - acc: 0.9477 - val_loss: 1.2422 - val_acc: 0.7324\n",
            "Epoch 14/40\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.1438 - acc: 0.9491 - val_loss: 1.2459 - val_acc: 0.7371\n",
            "Epoch 15/40\n",
            "40000/40000 [==============================] - 12s 300us/step - loss: 0.1322 - acc: 0.9525 - val_loss: 1.2886 - val_acc: 0.7154\n",
            "Epoch 16/40\n",
            "40000/40000 [==============================] - 12s 298us/step - loss: 0.1092 - acc: 0.9620 - val_loss: 1.3680 - val_acc: 0.7348\n",
            "Epoch 17/40\n",
            "40000/40000 [==============================] - 12s 300us/step - loss: 0.1046 - acc: 0.9632 - val_loss: 1.3877 - val_acc: 0.7331\n",
            "Epoch 18/40\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.1127 - acc: 0.9590 - val_loss: 1.4855 - val_acc: 0.7290\n",
            "Epoch 19/40\n",
            "40000/40000 [==============================] - 12s 300us/step - loss: 0.0947 - acc: 0.9671 - val_loss: 1.4615 - val_acc: 0.7248\n",
            "Epoch 20/40\n",
            "40000/40000 [==============================] - 12s 300us/step - loss: 0.1015 - acc: 0.9646 - val_loss: 1.4010 - val_acc: 0.7353\n",
            "Epoch 21/40\n",
            "40000/40000 [==============================] - 12s 300us/step - loss: 0.0773 - acc: 0.9728 - val_loss: 1.7024 - val_acc: 0.7192\n",
            "Epoch 22/40\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.0909 - acc: 0.9683 - val_loss: 1.6964 - val_acc: 0.7246\n",
            "Epoch 23/40\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.0777 - acc: 0.9729 - val_loss: 1.6670 - val_acc: 0.7345\n",
            "Epoch 24/40\n",
            "40000/40000 [==============================] - 12s 298us/step - loss: 0.0904 - acc: 0.9685 - val_loss: 1.6282 - val_acc: 0.7284\n",
            "Epoch 25/40\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.0763 - acc: 0.9734 - val_loss: 1.5943 - val_acc: 0.7314\n",
            "Epoch 26/40\n",
            "40000/40000 [==============================] - 12s 300us/step - loss: 0.0766 - acc: 0.9734 - val_loss: 1.7537 - val_acc: 0.7194\n",
            "Epoch 27/40\n",
            "40000/40000 [==============================] - 12s 300us/step - loss: 0.0767 - acc: 0.9734 - val_loss: 1.7371 - val_acc: 0.7277\n",
            "Epoch 28/40\n",
            "40000/40000 [==============================] - 12s 302us/step - loss: 0.0723 - acc: 0.9756 - val_loss: 1.7052 - val_acc: 0.7240\n",
            "Epoch 29/40\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.0756 - acc: 0.9747 - val_loss: 1.7587 - val_acc: 0.7293\n",
            "Epoch 30/40\n",
            "40000/40000 [==============================] - 12s 305us/step - loss: 0.0718 - acc: 0.9763 - val_loss: 1.8358 - val_acc: 0.7238\n",
            "Epoch 31/40\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.0687 - acc: 0.9763 - val_loss: 1.8430 - val_acc: 0.7308\n",
            "Epoch 32/40\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.0673 - acc: 0.9774 - val_loss: 1.8674 - val_acc: 0.7229\n",
            "Epoch 33/40\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.0662 - acc: 0.9783 - val_loss: 1.7415 - val_acc: 0.7342\n",
            "Epoch 34/40\n",
            "40000/40000 [==============================] - 12s 304us/step - loss: 0.0537 - acc: 0.9820 - val_loss: 1.8849 - val_acc: 0.7314\n",
            "Epoch 35/40\n",
            "40000/40000 [==============================] - 12s 300us/step - loss: 0.0694 - acc: 0.9768 - val_loss: 1.9707 - val_acc: 0.7071\n",
            "Epoch 36/40\n",
            "40000/40000 [==============================] - 12s 305us/step - loss: 0.0641 - acc: 0.9784 - val_loss: 1.8676 - val_acc: 0.7285\n",
            "Epoch 37/40\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.0623 - acc: 0.9792 - val_loss: 1.8125 - val_acc: 0.7341\n",
            "Epoch 38/40\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.0583 - acc: 0.9807 - val_loss: 1.8648 - val_acc: 0.7393\n",
            "Epoch 39/40\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.0610 - acc: 0.9799 - val_loss: 1.9127 - val_acc: 0.7276\n",
            "Epoch 40/40\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.0619 - acc: 0.9796 - val_loss: 1.7303 - val_acc: 0.7341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z0xXI48M5qfA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adding another layer doesn't increase validation accuracy.There is even more overfitting since the training accuracy is around 98% for the 40th epoch whereas it is just around 75% for validation data.\n",
        "\n",
        "Therefore, now we are going to include regularization, data augmentation and dropout one by one to the existing model with 4 layers in order to see how to validation accuracy improves and overfitting is minimized."
      ]
    },
    {
      "metadata": {
        "id": "TNRUlGqDInG5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Add Data Augmentation"
      ]
    },
    {
      "metadata": {
        "id": "qAZpDyf8OKNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "7e80d24c-41bf-4846-a2c3-daafed8106ea"
      },
      "cell_type": "code",
      "source": [
        "# set up the layers\n",
        "\n",
        "model = models.Sequential()\n",
        "#conv layers   \n",
        "#1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#3\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu',padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#4\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 307,786\n",
            "Trainable params: 307,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hSaXYN7mb4IX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eBpx2orPOf1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        },
        "outputId": "1603b636-870d-4bc5-bf74-370af1644f77"
      },
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "datagen = ImageDataGenerator(\n",
        "    #rescale=1./255,  #our image is already normalized so we dont need this\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "datagen.fit(train_images_norm)\n",
        "\n",
        "history = model.fit_generator(datagen.flow(train_images_norm, train_labels_norm, batch_size=64),\n",
        "                    steps_per_epoch=int(len(train_images_norm) / 64), epochs=epochs,\n",
        "                   verbose=1, validation_data=(val_images_norm, val_labels_norm))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 1.8152 - acc: 0.3275 - val_loss: 1.6358 - val_acc: 0.4227\n",
            "Epoch 2/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 1.5297 - acc: 0.4442 - val_loss: 1.2595 - val_acc: 0.5430\n",
            "Epoch 3/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 1.3918 - acc: 0.4975 - val_loss: 1.1232 - val_acc: 0.5886\n",
            "Epoch 4/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 1.3051 - acc: 0.5313 - val_loss: 1.2593 - val_acc: 0.5589\n",
            "Epoch 5/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 1.2511 - acc: 0.5555 - val_loss: 1.0172 - val_acc: 0.6355\n",
            "Epoch 6/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 1.1841 - acc: 0.5769 - val_loss: 1.0580 - val_acc: 0.6244\n",
            "Epoch 7/40\n",
            "625/625 [==============================] - 28s 46ms/step - loss: 1.1472 - acc: 0.5904 - val_loss: 0.9873 - val_acc: 0.6492\n",
            "Epoch 8/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 1.1072 - acc: 0.6056 - val_loss: 1.0493 - val_acc: 0.6400\n",
            "Epoch 9/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 1.0806 - acc: 0.6189 - val_loss: 0.9751 - val_acc: 0.6644\n",
            "Epoch 10/40\n",
            "625/625 [==============================] - 28s 46ms/step - loss: 1.0541 - acc: 0.6261 - val_loss: 0.9298 - val_acc: 0.6733\n",
            "Epoch 11/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 1.0316 - acc: 0.6347 - val_loss: 1.0073 - val_acc: 0.6551\n",
            "Epoch 12/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 1.0137 - acc: 0.6406 - val_loss: 0.9301 - val_acc: 0.6798\n",
            "Epoch 13/40\n",
            "625/625 [==============================] - 28s 46ms/step - loss: 0.9881 - acc: 0.6502 - val_loss: 0.9473 - val_acc: 0.6737\n",
            "Epoch 14/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.9720 - acc: 0.6582 - val_loss: 1.0401 - val_acc: 0.6526\n",
            "Epoch 15/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.9546 - acc: 0.6618 - val_loss: 0.9089 - val_acc: 0.6947\n",
            "Epoch 16/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.9466 - acc: 0.6658 - val_loss: 0.8221 - val_acc: 0.7150\n",
            "Epoch 17/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 0.9352 - acc: 0.6734 - val_loss: 0.8939 - val_acc: 0.6929\n",
            "Epoch 18/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.9258 - acc: 0.6751 - val_loss: 0.9843 - val_acc: 0.6711\n",
            "Epoch 19/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 0.9092 - acc: 0.6815 - val_loss: 0.7847 - val_acc: 0.7263\n",
            "Epoch 20/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 0.9032 - acc: 0.6839 - val_loss: 0.9093 - val_acc: 0.6986\n",
            "Epoch 21/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.8807 - acc: 0.6904 - val_loss: 0.7831 - val_acc: 0.7303\n",
            "Epoch 22/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.8781 - acc: 0.6904 - val_loss: 0.8129 - val_acc: 0.7229\n",
            "Epoch 23/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 0.8748 - acc: 0.6939 - val_loss: 0.8310 - val_acc: 0.7130\n",
            "Epoch 24/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 0.8666 - acc: 0.6987 - val_loss: 0.8288 - val_acc: 0.7195\n",
            "Epoch 25/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 0.8534 - acc: 0.6994 - val_loss: 0.8168 - val_acc: 0.7223\n",
            "Epoch 26/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 0.8509 - acc: 0.6991 - val_loss: 0.7463 - val_acc: 0.7457\n",
            "Epoch 27/40\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 0.8390 - acc: 0.7049 - val_loss: 0.8055 - val_acc: 0.7254\n",
            "Epoch 28/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.8374 - acc: 0.7077 - val_loss: 0.7688 - val_acc: 0.7401\n",
            "Epoch 29/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.8236 - acc: 0.7101 - val_loss: 0.7787 - val_acc: 0.7366\n",
            "Epoch 30/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.8249 - acc: 0.7110 - val_loss: 0.7800 - val_acc: 0.7399\n",
            "Epoch 31/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.8171 - acc: 0.7125 - val_loss: 0.7262 - val_acc: 0.7481\n",
            "Epoch 32/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.8117 - acc: 0.7130 - val_loss: 0.7923 - val_acc: 0.7324\n",
            "Epoch 33/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.8038 - acc: 0.7195 - val_loss: 0.8223 - val_acc: 0.7255\n",
            "Epoch 34/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.7990 - acc: 0.7226 - val_loss: 0.7708 - val_acc: 0.7391\n",
            "Epoch 35/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.7914 - acc: 0.7224 - val_loss: 0.8241 - val_acc: 0.7188\n",
            "Epoch 36/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.7884 - acc: 0.7255 - val_loss: 0.7646 - val_acc: 0.7425\n",
            "Epoch 37/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.7850 - acc: 0.7245 - val_loss: 0.8299 - val_acc: 0.7263\n",
            "Epoch 38/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.7812 - acc: 0.7245 - val_loss: 0.8688 - val_acc: 0.7147\n",
            "Epoch 39/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.7702 - acc: 0.7321 - val_loss: 0.7917 - val_acc: 0.7334\n",
            "Epoch 40/40\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.7693 - acc: 0.7290 - val_loss: 0.7128 - val_acc: 0.7564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U2Nzey546Yh6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Add more Layers, Regularization (kernal_regularizer, batch normalization and dropout) and Strides"
      ]
    },
    {
      "metadata": {
        "id": "1aMBqYWq980h",
        "colab_type": "code",
        "outputId": "fc20790e-9fc8-4570-934c-4a4b87e62723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "cell_type": "code",
      "source": [
        "#from keras import regularizers\n",
        "# set up the layers\n",
        "weight_decay = 1e-4\n",
        "model = models.Sequential()\n",
        "#conv layers   \n",
        "#1\n",
        "model.add(layers.Conv2D(32, (3, 3), strides = (1,1), activation='relu', padding = 'same', kernel_initializer='he_normal', kernel_regularizer= regularizers.l2(weight_decay), input_shape=(32, 32, 3)))\n",
        "model.add(layers.BatchNormalization())\n",
        "#2\n",
        "model.add(layers.Conv2D(32, (3, 3), strides = (1,1), activation='relu', padding = 'same', kernel_initializer='he_normal', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "#3\n",
        "model.add(layers.Conv2D(64, (3, 3), strides = (1,1), activation='relu',padding = 'same', kernel_initializer='he_normal', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.BatchNormalization())\n",
        "#4\n",
        "model.add(layers.Conv2D(64, (3, 3), strides = (1,1), activation='relu', padding = 'same', kernel_initializer='he_normal', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.3))\n",
        "#5\n",
        "model.add(layers.Conv2D(128, (3, 3), strides = (1,1), activation='relu', padding = 'same', kernel_initializer='he_normal', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.BatchNormalization())\n",
        "#6\n",
        "model.add(layers.Conv2D(128, (3, 3), strides = (1,1), activation='relu', padding = 'same', kernel_initializer='he_normal', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.4))\n",
        "#dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,362\n",
            "Trainable params: 551,466\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o7voAcZ-_6Mo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xhzyrOQM_6dC",
        "colab_type": "code",
        "outputId": "a6aff8fc-e131-42a5-dd75-3d843c4411a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2754
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 80\n",
        "history = model.fit(train_images_norm, \n",
        "                      train_labels_norm, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=64, \n",
        "                      validation_data=(val_images_norm, val_labels_norm))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/80\n",
            "40000/40000 [==============================] - 40s 990us/step - loss: 1.9697 - acc: 0.3159 - val_loss: 1.6191 - val_acc: 0.4530\n",
            "Epoch 2/80\n",
            "40000/40000 [==============================] - 36s 893us/step - loss: 1.5549 - acc: 0.4670 - val_loss: 1.2118 - val_acc: 0.5975\n",
            "Epoch 3/80\n",
            "40000/40000 [==============================] - 35s 886us/step - loss: 1.3383 - acc: 0.5577 - val_loss: 1.1041 - val_acc: 0.6389\n",
            "Epoch 4/80\n",
            "40000/40000 [==============================] - 33s 833us/step - loss: 1.1949 - acc: 0.6199 - val_loss: 0.9870 - val_acc: 0.6864\n",
            "Epoch 5/80\n",
            "40000/40000 [==============================] - 28s 692us/step - loss: 1.0926 - acc: 0.6594 - val_loss: 0.8855 - val_acc: 0.7246\n",
            "Epoch 6/80\n",
            "40000/40000 [==============================] - 35s 863us/step - loss: 1.0127 - acc: 0.6920 - val_loss: 0.8591 - val_acc: 0.7478\n",
            "Epoch 7/80\n",
            "40000/40000 [==============================] - 35s 875us/step - loss: 0.9643 - acc: 0.7110 - val_loss: 0.8981 - val_acc: 0.7353\n",
            "Epoch 8/80\n",
            "40000/40000 [==============================] - 35s 882us/step - loss: 0.9157 - acc: 0.7308 - val_loss: 0.8123 - val_acc: 0.7593\n",
            "Epoch 9/80\n",
            "40000/40000 [==============================] - 35s 880us/step - loss: 0.8771 - acc: 0.7466 - val_loss: 0.7576 - val_acc: 0.7840\n",
            "Epoch 10/80\n",
            "40000/40000 [==============================] - 35s 876us/step - loss: 0.8454 - acc: 0.7615 - val_loss: 0.7816 - val_acc: 0.7850\n",
            "Epoch 11/80\n",
            "40000/40000 [==============================] - 35s 870us/step - loss: 0.8111 - acc: 0.7733 - val_loss: 0.7530 - val_acc: 0.7956\n",
            "Epoch 12/80\n",
            "40000/40000 [==============================] - 35s 869us/step - loss: 0.7936 - acc: 0.7838 - val_loss: 0.7107 - val_acc: 0.8132\n",
            "Epoch 13/80\n",
            "40000/40000 [==============================] - 35s 884us/step - loss: 0.7701 - acc: 0.7935 - val_loss: 0.7452 - val_acc: 0.8048\n",
            "Epoch 14/80\n",
            "40000/40000 [==============================] - 35s 883us/step - loss: 0.7534 - acc: 0.8017 - val_loss: 0.7274 - val_acc: 0.8120\n",
            "Epoch 15/80\n",
            "40000/40000 [==============================] - 35s 884us/step - loss: 0.7340 - acc: 0.8076 - val_loss: 0.6990 - val_acc: 0.8211\n",
            "Epoch 16/80\n",
            "40000/40000 [==============================] - 35s 880us/step - loss: 0.7131 - acc: 0.8151 - val_loss: 0.6970 - val_acc: 0.8221\n",
            "Epoch 17/80\n",
            "40000/40000 [==============================] - 35s 884us/step - loss: 0.7002 - acc: 0.8215 - val_loss: 0.6920 - val_acc: 0.8274\n",
            "Epoch 18/80\n",
            "40000/40000 [==============================] - 35s 884us/step - loss: 0.6867 - acc: 0.8289 - val_loss: 0.7521 - val_acc: 0.8127\n",
            "Epoch 19/80\n",
            "40000/40000 [==============================] - 35s 881us/step - loss: 0.6793 - acc: 0.8305 - val_loss: 0.7654 - val_acc: 0.8082\n",
            "Epoch 20/80\n",
            "40000/40000 [==============================] - 35s 883us/step - loss: 0.6705 - acc: 0.8348 - val_loss: 0.7408 - val_acc: 0.8158\n",
            "Epoch 21/80\n",
            "40000/40000 [==============================] - 35s 883us/step - loss: 0.6604 - acc: 0.8398 - val_loss: 0.7868 - val_acc: 0.8041\n",
            "Epoch 22/80\n",
            "40000/40000 [==============================] - 35s 883us/step - loss: 0.6445 - acc: 0.8461 - val_loss: 0.7089 - val_acc: 0.8310\n",
            "Epoch 23/80\n",
            "40000/40000 [==============================] - 35s 880us/step - loss: 0.6390 - acc: 0.8474 - val_loss: 0.7430 - val_acc: 0.8233\n",
            "Epoch 24/80\n",
            "40000/40000 [==============================] - 35s 873us/step - loss: 0.6402 - acc: 0.8484 - val_loss: 0.7060 - val_acc: 0.8331\n",
            "Epoch 25/80\n",
            "40000/40000 [==============================] - 35s 881us/step - loss: 0.6305 - acc: 0.8501 - val_loss: 0.6809 - val_acc: 0.8404\n",
            "Epoch 26/80\n",
            "40000/40000 [==============================] - 35s 882us/step - loss: 0.6145 - acc: 0.8588 - val_loss: 0.7022 - val_acc: 0.8343\n",
            "Epoch 27/80\n",
            "40000/40000 [==============================] - 35s 882us/step - loss: 0.6063 - acc: 0.8610 - val_loss: 0.6979 - val_acc: 0.8412\n",
            "Epoch 28/80\n",
            "40000/40000 [==============================] - 35s 877us/step - loss: 0.6126 - acc: 0.8600 - val_loss: 0.7750 - val_acc: 0.8167\n",
            "Epoch 29/80\n",
            "40000/40000 [==============================] - 33s 837us/step - loss: 0.6050 - acc: 0.8624 - val_loss: 0.7200 - val_acc: 0.8325\n",
            "Epoch 30/80\n",
            "40000/40000 [==============================] - 28s 708us/step - loss: 0.6019 - acc: 0.8649 - val_loss: 0.7155 - val_acc: 0.8362\n",
            "Epoch 31/80\n",
            "40000/40000 [==============================] - 26s 661us/step - loss: 0.5960 - acc: 0.8656 - val_loss: 0.6952 - val_acc: 0.8430\n",
            "Epoch 32/80\n",
            "40000/40000 [==============================] - 27s 679us/step - loss: 0.5867 - acc: 0.8707 - val_loss: 0.6820 - val_acc: 0.8469\n",
            "Epoch 33/80\n",
            "40000/40000 [==============================] - 27s 667us/step - loss: 0.5859 - acc: 0.8714 - val_loss: 0.7207 - val_acc: 0.8357\n",
            "Epoch 34/80\n",
            "40000/40000 [==============================] - 27s 679us/step - loss: 0.5831 - acc: 0.8727 - val_loss: 0.7340 - val_acc: 0.8381\n",
            "Epoch 35/80\n",
            "40000/40000 [==============================] - 25s 636us/step - loss: 0.5699 - acc: 0.8754 - val_loss: 0.7197 - val_acc: 0.8430\n",
            "Epoch 36/80\n",
            "40000/40000 [==============================] - 26s 654us/step - loss: 0.5665 - acc: 0.8784 - val_loss: 0.6776 - val_acc: 0.8484\n",
            "Epoch 37/80\n",
            "40000/40000 [==============================] - 26s 652us/step - loss: 0.5616 - acc: 0.8800 - val_loss: 0.7218 - val_acc: 0.8415\n",
            "Epoch 38/80\n",
            "40000/40000 [==============================] - 26s 657us/step - loss: 0.5675 - acc: 0.8815 - val_loss: 0.7040 - val_acc: 0.8525\n",
            "Epoch 39/80\n",
            "40000/40000 [==============================] - 26s 647us/step - loss: 0.5622 - acc: 0.8822 - val_loss: 0.7100 - val_acc: 0.8472\n",
            "Epoch 40/80\n",
            "40000/40000 [==============================] - 27s 680us/step - loss: 0.5575 - acc: 0.8841 - val_loss: 0.6846 - val_acc: 0.8535\n",
            "Epoch 41/80\n",
            "40000/40000 [==============================] - 27s 663us/step - loss: 0.5513 - acc: 0.8871 - val_loss: 0.7483 - val_acc: 0.8448\n",
            "Epoch 42/80\n",
            "40000/40000 [==============================] - 28s 691us/step - loss: 0.5568 - acc: 0.8831 - val_loss: 0.8858 - val_acc: 0.8085\n",
            "Epoch 43/80\n",
            "40000/40000 [==============================] - 35s 865us/step - loss: 0.5492 - acc: 0.8875 - val_loss: 0.7005 - val_acc: 0.8499\n",
            "Epoch 44/80\n",
            "40000/40000 [==============================] - 35s 877us/step - loss: 0.5533 - acc: 0.8875 - val_loss: 0.7206 - val_acc: 0.8472\n",
            "Epoch 45/80\n",
            "40000/40000 [==============================] - 35s 872us/step - loss: 0.5486 - acc: 0.8872 - val_loss: 0.7103 - val_acc: 0.8465\n",
            "Epoch 46/80\n",
            "40000/40000 [==============================] - 33s 813us/step - loss: 0.5418 - acc: 0.8911 - val_loss: 0.6889 - val_acc: 0.8525\n",
            "Epoch 47/80\n",
            "40000/40000 [==============================] - 26s 641us/step - loss: 0.5367 - acc: 0.8906 - val_loss: 0.6998 - val_acc: 0.8536\n",
            "Epoch 48/80\n",
            "40000/40000 [==============================] - 25s 635us/step - loss: 0.5432 - acc: 0.8911 - val_loss: 0.7031 - val_acc: 0.8529\n",
            "Epoch 49/80\n",
            "40000/40000 [==============================] - 27s 663us/step - loss: 0.5373 - acc: 0.8932 - val_loss: 0.6674 - val_acc: 0.8586\n",
            "Epoch 50/80\n",
            "40000/40000 [==============================] - 25s 636us/step - loss: 0.5401 - acc: 0.8930 - val_loss: 0.7177 - val_acc: 0.8444\n",
            "Epoch 51/80\n",
            "40000/40000 [==============================] - 26s 660us/step - loss: 0.5301 - acc: 0.8954 - val_loss: 0.7235 - val_acc: 0.8504\n",
            "Epoch 52/80\n",
            "40000/40000 [==============================] - 26s 661us/step - loss: 0.5273 - acc: 0.8960 - val_loss: 0.7022 - val_acc: 0.8559\n",
            "Epoch 53/80\n",
            "40000/40000 [==============================] - 27s 682us/step - loss: 0.5252 - acc: 0.8960 - val_loss: 0.6848 - val_acc: 0.8557\n",
            "Epoch 54/80\n",
            "40000/40000 [==============================] - 26s 662us/step - loss: 0.5222 - acc: 0.8989 - val_loss: 0.6955 - val_acc: 0.8564\n",
            "Epoch 55/80\n",
            "40000/40000 [==============================] - 27s 680us/step - loss: 0.5259 - acc: 0.8973 - val_loss: 0.7031 - val_acc: 0.8532\n",
            "Epoch 56/80\n",
            "40000/40000 [==============================] - 27s 663us/step - loss: 0.5166 - acc: 0.9002 - val_loss: 0.7077 - val_acc: 0.8572\n",
            "Epoch 57/80\n",
            "40000/40000 [==============================] - 27s 678us/step - loss: 0.5276 - acc: 0.8988 - val_loss: 0.7403 - val_acc: 0.8438\n",
            "Epoch 58/80\n",
            "40000/40000 [==============================] - 27s 673us/step - loss: 0.5187 - acc: 0.8998 - val_loss: 0.6898 - val_acc: 0.8564\n",
            "Epoch 59/80\n",
            "40000/40000 [==============================] - 27s 681us/step - loss: 0.5196 - acc: 0.8996 - val_loss: 0.6807 - val_acc: 0.8634\n",
            "Epoch 60/80\n",
            "40000/40000 [==============================] - 26s 642us/step - loss: 0.5207 - acc: 0.9011 - val_loss: 0.7295 - val_acc: 0.8548\n",
            "Epoch 61/80\n",
            "40000/40000 [==============================] - 27s 679us/step - loss: 0.5059 - acc: 0.9040 - val_loss: 0.7034 - val_acc: 0.8527\n",
            "Epoch 62/80\n",
            "40000/40000 [==============================] - 26s 651us/step - loss: 0.5122 - acc: 0.9010 - val_loss: 0.7119 - val_acc: 0.8536\n",
            "Epoch 63/80\n",
            "40000/40000 [==============================] - 28s 688us/step - loss: 0.5107 - acc: 0.9023 - val_loss: 0.7025 - val_acc: 0.8552\n",
            "Epoch 64/80\n",
            "40000/40000 [==============================] - 35s 870us/step - loss: 0.5097 - acc: 0.9015 - val_loss: 0.6988 - val_acc: 0.8523\n",
            "Epoch 65/80\n",
            "40000/40000 [==============================] - 35s 879us/step - loss: 0.5117 - acc: 0.9035 - val_loss: 0.7852 - val_acc: 0.8446\n",
            "Epoch 66/80\n",
            "40000/40000 [==============================] - 35s 866us/step - loss: 0.5144 - acc: 0.9017 - val_loss: 0.6908 - val_acc: 0.8622\n",
            "Epoch 67/80\n",
            "40000/40000 [==============================] - 27s 668us/step - loss: 0.5074 - acc: 0.9052 - val_loss: 0.6621 - val_acc: 0.8608\n",
            "Epoch 68/80\n",
            "40000/40000 [==============================] - 33s 816us/step - loss: 0.5101 - acc: 0.9032 - val_loss: 0.6938 - val_acc: 0.8647\n",
            "Epoch 69/80\n",
            "40000/40000 [==============================] - 26s 656us/step - loss: 0.5033 - acc: 0.9063 - val_loss: 0.6740 - val_acc: 0.8636\n",
            "Epoch 70/80\n",
            "40000/40000 [==============================] - 26s 642us/step - loss: 0.4995 - acc: 0.9091 - val_loss: 0.7018 - val_acc: 0.8570\n",
            "Epoch 71/80\n",
            "40000/40000 [==============================] - 27s 663us/step - loss: 0.5055 - acc: 0.9059 - val_loss: 0.7183 - val_acc: 0.8544\n",
            "Epoch 72/80\n",
            "40000/40000 [==============================] - 35s 875us/step - loss: 0.5035 - acc: 0.9072 - val_loss: 0.7166 - val_acc: 0.8571\n",
            "Epoch 73/80\n",
            "40000/40000 [==============================] - 35s 878us/step - loss: 0.5025 - acc: 0.9059 - val_loss: 0.6734 - val_acc: 0.8661\n",
            "Epoch 74/80\n",
            "40000/40000 [==============================] - 35s 873us/step - loss: 0.5014 - acc: 0.9084 - val_loss: 0.6656 - val_acc: 0.8650\n",
            "Epoch 75/80\n",
            "40000/40000 [==============================] - 35s 865us/step - loss: 0.5023 - acc: 0.9082 - val_loss: 0.6886 - val_acc: 0.8599\n",
            "Epoch 76/80\n",
            "40000/40000 [==============================] - 34s 849us/step - loss: 0.4959 - acc: 0.9095 - val_loss: 0.6895 - val_acc: 0.8680\n",
            "Epoch 77/80\n",
            "40000/40000 [==============================] - 36s 889us/step - loss: 0.5033 - acc: 0.9077 - val_loss: 0.7118 - val_acc: 0.8560\n",
            "Epoch 78/80\n",
            "40000/40000 [==============================] - 36s 898us/step - loss: 0.4964 - acc: 0.9097 - val_loss: 0.7662 - val_acc: 0.8506\n",
            "Epoch 79/80\n",
            "40000/40000 [==============================] - 36s 891us/step - loss: 0.5005 - acc: 0.9082 - val_loss: 0.6950 - val_acc: 0.8642\n",
            "Epoch 80/80\n",
            "40000/40000 [==============================] - 33s 824us/step - loss: 0.4946 - acc: 0.9099 - val_loss: 0.7520 - val_acc: 0.8487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S2NfzPoCo12s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "outputId": "82cc1062-d6d1-47ac-ef69-2480e819c6a5"
      },
      "cell_type": "code",
      "source": [
        "#print(epochs)\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# training and validation accuracy\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# training and validation loss\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAfJOiqHeA+/0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "pOki6JwFjtIY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Model Performance on Test data using simple hold validation"
      ]
    },
    {
      "metadata": {
        "id": "kLX_ovaNj0ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "16f98aab-f109-40da-a6d2-0ae110427afa"
      },
      "cell_type": "code",
      "source": [
        "result = model.evaluate(test_images_norm, test_labels_norm, verbose=1)\n",
        "print('Test accuracy:', result[1])\n",
        "print('Test loss:', result[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 259us/step\n",
            "Test accuracy: 0.8448\n",
            "Test loss: 0.7580705450057983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cEU96zN_gSMY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###K-fold validation "
      ]
    },
    {
      "metadata": {
        "id": "39OAAf39gkHn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}