{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gshah8/UCF/blob/master/Machine_Learning/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5vSpuR2h9REm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# HW 2\n",
        "\n",
        "The goal of this homework is to create a convolutional neural network for the CIFAR10 data set. \n",
        "See [this colab notebook](https://colab.research.google.com/drive/1LZZviWOzvchcXRdZi2IBx3KOpQOzLalf) how to load the CIFAR data in Keras.\n",
        "\n",
        "You should not use any pretrained convnets that come with Keras. You have to create and train your own convnets with Keras from scratch.\n",
        "\n",
        "## Simple hold-out validation\n",
        "\n",
        "Make sure that the data is divided into: \n",
        "\n",
        "- training set (80%)\n",
        "- validation set (20%)\n",
        "- test set. \n",
        "\n",
        "Use the training set to train your neural networks. Evaluate their performance on the validation data set. \n",
        "\n",
        "After trying several different architectures, choose the one that performs\n",
        "best of the validation set. Try at least four different architectures by using data augmentation, using dropout, varying the number of layers, the number of filters, etc.\n",
        "\n",
        "Train this final architecture on the data from the training set and validation set and evaluate its performance on \n",
        "the test set.\n",
        "\n",
        "## k-fold validation\n",
        "\n",
        "Reevaluate your best architecture using k-fold validation with k=5, that is, the size of the validation fold is 20%. Does the accuracy/loss obtain by k-fold validation differ from the accuracy/loss obtain by simple hold-out validation."
      ]
    },
    {
      "metadata": {
        "id": "tGt5GSXu_g9t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading the CIFAR10 data set\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GaciVEq0_dts",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-AYEf3umAHQm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exploring the format of the CIFAR10 data set"
      ]
    },
    {
      "metadata": {
        "id": "p1hNMiPtAIsN",
        "colab_type": "code",
        "outputId": "32b6d6ef-9820-49d2-e047-dbdc01e99dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "J6KJNpLlAtLb",
        "colab_type": "code",
        "outputId": "5e548d2b-3ad4-4837-f648-487665dcd362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_images.ndim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "8_SDVSLrAx1L",
        "colab_type": "code",
        "outputId": "8d42d8e1-63f7-41f8-d3f5-3d06113ad43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "14iRg_dJA0Iv",
        "colab_type": "code",
        "outputId": "a4816eb4-8449-415c-8e1f-58a685383587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_labels.ndim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "Mqbp1flDTvGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Using Simple Hold Validation for the models below"
      ]
    },
    {
      "metadata": {
        "id": "ghUwL-nmUZx8",
        "colab_type": "code",
        "outputId": "943db875-0974-4f91-a308-4556ebce0156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#divide training data into training and validation data\n",
        "rand_idx = np.random.permutation(len(train_images))\n",
        "val_idx = rand_idx[0:2000]\n",
        "train_idx = rand_idx[2000:]\n",
        "\n",
        "train_images_new, train_labels_new = train_images[train_idx] , train_labels[train_idx]\n",
        "val_images, val_labels = train_images[val_idx] , train_labels[val_idx]\n",
        "\n",
        "#normalize training and validation data\n",
        "train_images_norm = train_images_new/255.0\n",
        "val_images_norm = val_images/255.0\n",
        "\n",
        "#train_images_norm.shape\n",
        "#train_images_norm.shape\n",
        "train_labels_new[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "FbOE5y_-EzOV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Preprocess test data"
      ]
    },
    {
      "metadata": {
        "id": "w4u6Vq_KE6Oe",
        "colab_type": "code",
        "outputId": "87fd45bf-b1f7-4600-fe84-53279aca1a6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "#train_images_norm = train_images/255\n",
        "test_images_norm = test_images/255.0\n",
        "\n",
        "#one-hot encoding\n",
        "train_labels_norm = to_categorical(train_labels_new)\n",
        "val_labels_norm = to_categorical(val_labels)\n",
        "test_labels_norm = to_categorical(test_labels)\n",
        "\n",
        "train_labels_norm[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "9vynlXErFcqO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Build a basic model (without Data Augmentation and Dropout)"
      ]
    },
    {
      "metadata": {
        "id": "4d7o1oJLFeqm",
        "colab_type": "code",
        "outputId": "6d4f0c15-42d3-4159-ddc3-211a1102975e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# set up the layers\n",
        "\n",
        "model = models.Sequential()\n",
        "#conv layers   \n",
        "#1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#3\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_98 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_84 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_99 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_85 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_100 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_86 (MaxPooling (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 122,570\n",
            "Trainable params: 122,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mXpTCFSKH-0Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Compile the Model"
      ]
    },
    {
      "metadata": {
        "id": "UY6Yl69XH4b4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jDH1M98B_Zb2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Train the Model"
      ]
    },
    {
      "metadata": {
        "id": "ULo_pCDVIJd_",
        "colab_type": "code",
        "outputId": "3815420d-5519-435a-c66c-65cbc25b2e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "cell_type": "code",
      "source": [
        "#epochs = 20\n",
        "#history = model.fit(train_images_norm, \n",
        "#                      train_labels_norm, \n",
        "#                      epochs=epochs,  \n",
        "#                      validation_data=(val_images_norm, val_labels))\n",
        "\n",
        "#epochs = 20\n",
        "#history = model.fit(train_images_norm, \n",
        "#                      train_labels_norm, \n",
        "#                      epochs=epochs,  \n",
        "#                      validation_data=(val_images_norm, val_labels))\n",
        "\n",
        "\n",
        "\n",
        "epochs = 20\n",
        "history = model.fit(train_images_norm, \n",
        "                      train_labels_norm, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=64, \n",
        "                      validation_data=(val_images_norm, val_labels_norm))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 2000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 12s 243us/step - loss: 1.5230 - acc: 0.4483 - val_loss: 1.2299 - val_acc: 0.5475\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 11s 219us/step - loss: 1.1205 - acc: 0.6035 - val_loss: 1.0132 - val_acc: 0.6355\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 10s 218us/step - loss: 0.9532 - acc: 0.6671 - val_loss: 0.9297 - val_acc: 0.6585\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.8555 - acc: 0.7036 - val_loss: 0.9094 - val_acc: 0.6795\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 10s 217us/step - loss: 0.7809 - acc: 0.7288 - val_loss: 0.8670 - val_acc: 0.6995\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 10s 217us/step - loss: 0.7153 - acc: 0.7494 - val_loss: 0.8177 - val_acc: 0.7240\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.6592 - acc: 0.7708 - val_loss: 0.8152 - val_acc: 0.7255\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 10s 216us/step - loss: 0.6175 - acc: 0.7843 - val_loss: 0.8027 - val_acc: 0.7310\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 10s 214us/step - loss: 0.5705 - acc: 0.8013 - val_loss: 0.7943 - val_acc: 0.7380\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 10s 214us/step - loss: 0.5334 - acc: 0.8141 - val_loss: 0.8051 - val_acc: 0.7395\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 10s 216us/step - loss: 0.4956 - acc: 0.8262 - val_loss: 0.8260 - val_acc: 0.7315\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 10s 216us/step - loss: 0.4599 - acc: 0.8393 - val_loss: 0.8562 - val_acc: 0.7425\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 10s 216us/step - loss: 0.4315 - acc: 0.8471 - val_loss: 0.8889 - val_acc: 0.7370\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.3988 - acc: 0.8588 - val_loss: 0.8721 - val_acc: 0.7430\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 10s 216us/step - loss: 0.3696 - acc: 0.8688 - val_loss: 0.8761 - val_acc: 0.7470\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.3438 - acc: 0.8795 - val_loss: 0.9569 - val_acc: 0.7335\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.3213 - acc: 0.8857 - val_loss: 0.9996 - val_acc: 0.7360\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.2892 - acc: 0.8968 - val_loss: 1.0538 - val_acc: 0.7295\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.2703 - acc: 0.9037 - val_loss: 1.0773 - val_acc: 0.7275\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.2554 - acc: 0.9094 - val_loss: 1.0919 - val_acc: 0.7405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B-dIySPtN-Gj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can observe that the model is clearly overfitted since the training accuracy is increasing as we increase the number of epochs but the validation accuracy is not increasing.\n",
        "\n",
        "Now, we will try to improve the model by using the four following architectures:\n",
        "1. increasing the number of convolutional layers\n",
        "2. Adding more filters\n",
        "3. Data Augmentation\n",
        "4. Dropout\n",
        "\n",
        "We will add the above mentioned architectures one by one and observe the training and validation accuracy.\n",
        "In the end, as a final check, we will run the model for test data."
      ]
    },
    {
      "metadata": {
        "id": "kHsI-SikNtfQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###1. Increase the number of convolutional layers"
      ]
    },
    {
      "metadata": {
        "id": "pTnpHLaERnpt",
        "colab_type": "code",
        "outputId": "dd51b4e9-27c0-4bb8-8b80-1d86762a8dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# set up the layers\n",
        "\n",
        "model = models.Sequential()\n",
        "#conv layers   \n",
        "#1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#3\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu',padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#4\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_91 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_77 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_78 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_93 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_79 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_94 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_80 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_20 (Flatten)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 307,786\n",
            "Trainable params: 307,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wEx0Pl9CQlCE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T7RPGQ7ZQqcV",
        "colab_type": "code",
        "outputId": "fe2faa7b-a092-4323-d2cf-e888d406d19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1421
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "history = model.fit(train_images_norm, \n",
        "                      train_labels_norm, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=64, \n",
        "                      validation_data=(val_images_norm, val_labels_norm))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 2000 samples\n",
            "Epoch 1/40\n",
            "48000/48000 [==============================] - 16s 334us/step - loss: 1.5184 - acc: 0.4419 - val_loss: 1.1870 - val_acc: 0.5580\n",
            "Epoch 2/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 1.0602 - acc: 0.6225 - val_loss: 0.9539 - val_acc: 0.6490\n",
            "Epoch 3/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.8468 - acc: 0.7018 - val_loss: 0.8437 - val_acc: 0.7095\n",
            "Epoch 4/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.7225 - acc: 0.7469 - val_loss: 0.9177 - val_acc: 0.6865\n",
            "Epoch 5/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.6219 - acc: 0.7812 - val_loss: 0.8103 - val_acc: 0.7235\n",
            "Epoch 6/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.5327 - acc: 0.8119 - val_loss: 0.7843 - val_acc: 0.7415\n",
            "Epoch 7/40\n",
            "48000/48000 [==============================] - 14s 301us/step - loss: 0.4543 - acc: 0.8398 - val_loss: 0.7438 - val_acc: 0.7595\n",
            "Epoch 8/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.3872 - acc: 0.8627 - val_loss: 0.7900 - val_acc: 0.7565\n",
            "Epoch 9/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.3271 - acc: 0.8850 - val_loss: 0.8384 - val_acc: 0.7535\n",
            "Epoch 10/40\n",
            "48000/48000 [==============================] - 14s 301us/step - loss: 0.2793 - acc: 0.8997 - val_loss: 0.9169 - val_acc: 0.7495\n",
            "Epoch 11/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.2377 - acc: 0.9135 - val_loss: 1.0212 - val_acc: 0.7500\n",
            "Epoch 12/40\n",
            "48000/48000 [==============================] - 14s 301us/step - loss: 0.2066 - acc: 0.9265 - val_loss: 1.0355 - val_acc: 0.7470\n",
            "Epoch 13/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.1693 - acc: 0.9400 - val_loss: 1.0887 - val_acc: 0.7555\n",
            "Epoch 14/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.1640 - acc: 0.9411 - val_loss: 1.2274 - val_acc: 0.7335\n",
            "Epoch 15/40\n",
            "48000/48000 [==============================] - 14s 301us/step - loss: 0.1354 - acc: 0.9514 - val_loss: 1.2483 - val_acc: 0.7470\n",
            "Epoch 16/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.1371 - acc: 0.9512 - val_loss: 1.3656 - val_acc: 0.7370\n",
            "Epoch 17/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.1260 - acc: 0.9542 - val_loss: 1.3459 - val_acc: 0.7545\n",
            "Epoch 18/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.1181 - acc: 0.9579 - val_loss: 1.3833 - val_acc: 0.7390\n",
            "Epoch 19/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.1101 - acc: 0.9612 - val_loss: 1.5523 - val_acc: 0.7225\n",
            "Epoch 20/40\n",
            "48000/48000 [==============================] - 14s 301us/step - loss: 0.1088 - acc: 0.9608 - val_loss: 1.4369 - val_acc: 0.7470\n",
            "Epoch 21/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.0943 - acc: 0.9662 - val_loss: 1.6102 - val_acc: 0.7400\n",
            "Epoch 22/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.1006 - acc: 0.9654 - val_loss: 1.5217 - val_acc: 0.7485\n",
            "Epoch 23/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.0973 - acc: 0.9664 - val_loss: 1.5881 - val_acc: 0.7380\n",
            "Epoch 24/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.0884 - acc: 0.9697 - val_loss: 1.5520 - val_acc: 0.7450\n",
            "Epoch 25/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0869 - acc: 0.9698 - val_loss: 1.5926 - val_acc: 0.7330\n",
            "Epoch 26/40\n",
            "48000/48000 [==============================] - 14s 297us/step - loss: 0.0806 - acc: 0.9728 - val_loss: 1.6262 - val_acc: 0.7410\n",
            "Epoch 27/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0901 - acc: 0.9687 - val_loss: 1.5559 - val_acc: 0.7530\n",
            "Epoch 28/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.0688 - acc: 0.9764 - val_loss: 1.7931 - val_acc: 0.7405\n",
            "Epoch 29/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.0894 - acc: 0.9696 - val_loss: 1.6769 - val_acc: 0.7480\n",
            "Epoch 30/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0806 - acc: 0.9723 - val_loss: 1.6999 - val_acc: 0.7425\n",
            "Epoch 31/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.0682 - acc: 0.9764 - val_loss: 1.7562 - val_acc: 0.7390\n",
            "Epoch 32/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0735 - acc: 0.9745 - val_loss: 1.8480 - val_acc: 0.7400\n",
            "Epoch 33/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0831 - acc: 0.9715 - val_loss: 1.7513 - val_acc: 0.7425\n",
            "Epoch 34/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.0678 - acc: 0.9773 - val_loss: 1.6725 - val_acc: 0.7435\n",
            "Epoch 35/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.0679 - acc: 0.9768 - val_loss: 1.7472 - val_acc: 0.7485\n",
            "Epoch 36/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0669 - acc: 0.9775 - val_loss: 1.7366 - val_acc: 0.7510\n",
            "Epoch 37/40\n",
            "48000/48000 [==============================] - 14s 302us/step - loss: 0.0655 - acc: 0.9783 - val_loss: 1.8600 - val_acc: 0.7305\n",
            "Epoch 38/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0705 - acc: 0.9764 - val_loss: 1.8105 - val_acc: 0.7530\n",
            "Epoch 39/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.0700 - acc: 0.9771 - val_loss: 1.7070 - val_acc: 0.7545\n",
            "Epoch 40/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0604 - acc: 0.9799 - val_loss: 1.7302 - val_acc: 0.7475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z0xXI48M5qfA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adding another layer doesn't increase validation accuracy.There is even more overfitting since the training accuracy is around 98% for the 40th epoch whereas it is just around 75% for validation data.\n",
        "\n",
        "Therefore, now we are going to include regularization, data augmentation and dropout one by one to the existing model with 4 layers in order to see how to validation accuracy improves and overfitting is minimized."
      ]
    },
    {
      "metadata": {
        "id": "U2Nzey546Yh6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Add Regularization"
      ]
    },
    {
      "metadata": {
        "id": "1aMBqYWq980h",
        "colab_type": "code",
        "outputId": "23855d8e-5a16-4960-c9f0-4cf3db43f05c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "# set up the layers\n",
        "weight_decay = 1e-4\n",
        "model = models.Sequential()\n",
        "#conv layers   \n",
        "#1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', kernel_regularizer= regularizers.l2(weight_decay), input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#3\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu',padding = 'same', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#4\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_107 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_92 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_108 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_93 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_109 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_94 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_110 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_95 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 307,786\n",
            "Trainable params: 307,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o7voAcZ-_6Mo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xhzyrOQM_6dC",
        "colab_type": "code",
        "outputId": "83076358-f857-4410-e08f-e4a9c6889cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1421
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "history = model.fit(train_images_norm, \n",
        "                      train_labels_norm, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=64, \n",
        "                      validation_data=(val_images_norm, val_labels_norm))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 2000 samples\n",
            "Epoch 1/40\n",
            "48000/48000 [==============================] - 16s 336us/step - loss: 1.5280 - acc: 0.4500 - val_loss: 1.2838 - val_acc: 0.5445\n",
            "Epoch 2/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 1.1128 - acc: 0.6173 - val_loss: 1.0010 - val_acc: 0.6530\n",
            "Epoch 3/40\n",
            "48000/48000 [==============================] - 15s 308us/step - loss: 0.9257 - acc: 0.6899 - val_loss: 0.8848 - val_acc: 0.7070\n",
            "Epoch 4/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.8100 - acc: 0.7372 - val_loss: 0.8429 - val_acc: 0.7310\n",
            "Epoch 5/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.7256 - acc: 0.7685 - val_loss: 0.8397 - val_acc: 0.7220\n",
            "Epoch 6/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.6567 - acc: 0.7932 - val_loss: 0.7882 - val_acc: 0.7525\n",
            "Epoch 7/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.6021 - acc: 0.8151 - val_loss: 0.8284 - val_acc: 0.7530\n",
            "Epoch 8/40\n",
            "48000/48000 [==============================] - 15s 308us/step - loss: 0.5519 - acc: 0.8352 - val_loss: 0.8492 - val_acc: 0.7540\n",
            "Epoch 9/40\n",
            "48000/48000 [==============================] - 15s 305us/step - loss: 0.5036 - acc: 0.8545 - val_loss: 0.8855 - val_acc: 0.7490\n",
            "Epoch 10/40\n",
            "48000/48000 [==============================] - 15s 304us/step - loss: 0.4563 - acc: 0.8737 - val_loss: 1.0073 - val_acc: 0.7360\n",
            "Epoch 11/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.4235 - acc: 0.8883 - val_loss: 0.9329 - val_acc: 0.7530\n",
            "Epoch 12/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.3839 - acc: 0.9025 - val_loss: 1.0544 - val_acc: 0.7525\n",
            "Epoch 13/40\n",
            "48000/48000 [==============================] - 15s 308us/step - loss: 0.3662 - acc: 0.9099 - val_loss: 1.0672 - val_acc: 0.7595\n",
            "Epoch 14/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.3516 - acc: 0.9187 - val_loss: 1.1120 - val_acc: 0.7420\n",
            "Epoch 15/40\n",
            "48000/48000 [==============================] - 15s 305us/step - loss: 0.3375 - acc: 0.9257 - val_loss: 1.2548 - val_acc: 0.7360\n",
            "Epoch 16/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.3227 - acc: 0.9311 - val_loss: 1.2152 - val_acc: 0.7320\n",
            "Epoch 17/40\n",
            "48000/48000 [==============================] - 15s 305us/step - loss: 0.3112 - acc: 0.9372 - val_loss: 1.2858 - val_acc: 0.7355\n",
            "Epoch 18/40\n",
            "48000/48000 [==============================] - 15s 308us/step - loss: 0.3076 - acc: 0.9415 - val_loss: 1.4021 - val_acc: 0.7280\n",
            "Epoch 19/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2952 - acc: 0.9460 - val_loss: 1.3860 - val_acc: 0.7385\n",
            "Epoch 20/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.3019 - acc: 0.9449 - val_loss: 1.4411 - val_acc: 0.7490\n",
            "Epoch 21/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2964 - acc: 0.9484 - val_loss: 1.4191 - val_acc: 0.7400\n",
            "Epoch 22/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2831 - acc: 0.9539 - val_loss: 1.4541 - val_acc: 0.7415\n",
            "Epoch 23/40\n",
            "48000/48000 [==============================] - 15s 308us/step - loss: 0.2880 - acc: 0.9537 - val_loss: 1.5027 - val_acc: 0.7435\n",
            "Epoch 24/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2896 - acc: 0.9536 - val_loss: 1.4449 - val_acc: 0.7430\n",
            "Epoch 25/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2800 - acc: 0.9582 - val_loss: 1.4841 - val_acc: 0.7535\n",
            "Epoch 26/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2849 - acc: 0.9569 - val_loss: 1.4062 - val_acc: 0.7525\n",
            "Epoch 27/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2843 - acc: 0.9584 - val_loss: 1.5356 - val_acc: 0.7455\n",
            "Epoch 28/40\n",
            "48000/48000 [==============================] - 15s 311us/step - loss: 0.2797 - acc: 0.9601 - val_loss: 1.4867 - val_acc: 0.7385\n",
            "Epoch 29/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2830 - acc: 0.9610 - val_loss: 1.5011 - val_acc: 0.7500\n",
            "Epoch 30/40\n",
            "48000/48000 [==============================] - 15s 305us/step - loss: 0.2806 - acc: 0.9623 - val_loss: 1.5158 - val_acc: 0.7480\n",
            "Epoch 31/40\n",
            "48000/48000 [==============================] - 15s 305us/step - loss: 0.2825 - acc: 0.9611 - val_loss: 1.5289 - val_acc: 0.7445\n",
            "Epoch 32/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2733 - acc: 0.9649 - val_loss: 1.5470 - val_acc: 0.7415\n",
            "Epoch 33/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2846 - acc: 0.9619 - val_loss: 1.5867 - val_acc: 0.7540\n",
            "Epoch 34/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2756 - acc: 0.9641 - val_loss: 1.5374 - val_acc: 0.7465\n",
            "Epoch 35/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2815 - acc: 0.9640 - val_loss: 1.5772 - val_acc: 0.7520\n",
            "Epoch 36/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2673 - acc: 0.9680 - val_loss: 1.6316 - val_acc: 0.7475\n",
            "Epoch 37/40\n",
            "48000/48000 [==============================] - 15s 305us/step - loss: 0.2708 - acc: 0.9676 - val_loss: 1.5794 - val_acc: 0.7460\n",
            "Epoch 38/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2783 - acc: 0.9645 - val_loss: 1.6266 - val_acc: 0.7365\n",
            "Epoch 39/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2795 - acc: 0.9653 - val_loss: 1.5929 - val_acc: 0.7405\n",
            "Epoch 40/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2699 - acc: 0.9681 - val_loss: 1.6162 - val_acc: 0.7450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8OeuocpxB5iH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adding regulaizer reduces overfitting just by a little bit (1%). We will continue adding more architectures"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lKMFLIbFId5D"
      },
      "cell_type": "markdown",
      "source": [
        "###3. Add Batch Normalization"
      ]
    },
    {
      "metadata": {
        "id": "0CsLU5AyCygl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "f36d7862-263b-4e06-9d3b-3d51207da736"
      },
      "cell_type": "code",
      "source": [
        "#from keras import regularizers\n",
        "# set up the layers\n",
        "weight_decay = 1e-4\n",
        "model = models.Sequential()\n",
        "#conv layers   \n",
        "#1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', kernel_regularizer= regularizers.l2(weight_decay), input_shape=(32, 32, 3)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#3\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu',padding = 'same', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#4\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 309,194\n",
            "Trainable params: 308,490\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CGffbKMgEV11",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SbO5gB9_EY9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        },
        "outputId": "7fedc305-d38d-4226-c9e6-0e93efec386a"
      },
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "history = model.fit(train_images_norm, \n",
        "                      train_labels_norm, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=64, \n",
        "                      validation_data=(val_images_norm, val_labels_norm))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 48000 samples, validate on 2000 samples\n",
            "Epoch 1/40\n",
            "48000/48000 [==============================] - 25s 520us/step - loss: 1.2435 - acc: 0.5696 - val_loss: 1.1114 - val_acc: 0.6220\n",
            "Epoch 2/40\n",
            "48000/48000 [==============================] - 21s 445us/step - loss: 0.8692 - acc: 0.7105 - val_loss: 0.8628 - val_acc: 0.7065\n",
            "Epoch 3/40\n",
            "48000/48000 [==============================] - 21s 442us/step - loss: 0.7144 - acc: 0.7675 - val_loss: 1.0025 - val_acc: 0.6850\n",
            "Epoch 4/40\n",
            "48000/48000 [==============================] - 21s 447us/step - loss: 0.6043 - acc: 0.8079 - val_loss: 0.9745 - val_acc: 0.6980\n",
            "Epoch 5/40\n",
            "48000/48000 [==============================] - 21s 448us/step - loss: 0.5184 - acc: 0.8432 - val_loss: 0.9533 - val_acc: 0.7105\n",
            "Epoch 6/40\n",
            "48000/48000 [==============================] - 21s 442us/step - loss: 0.4445 - acc: 0.8731 - val_loss: 0.8958 - val_acc: 0.7540\n",
            "Epoch 7/40\n",
            "48000/48000 [==============================] - 21s 445us/step - loss: 0.3871 - acc: 0.8966 - val_loss: 0.9129 - val_acc: 0.7655\n",
            "Epoch 8/40\n",
            "48000/48000 [==============================] - 21s 438us/step - loss: 0.3470 - acc: 0.9155 - val_loss: 1.0380 - val_acc: 0.7475\n",
            "Epoch 9/40\n",
            "48000/48000 [==============================] - 21s 447us/step - loss: 0.3256 - acc: 0.9259 - val_loss: 1.3678 - val_acc: 0.6930\n",
            "Epoch 10/40\n",
            "48000/48000 [==============================] - 21s 440us/step - loss: 0.2952 - acc: 0.9394 - val_loss: 1.2336 - val_acc: 0.7335\n",
            "Epoch 11/40\n",
            "48000/48000 [==============================] - 21s 442us/step - loss: 0.2884 - acc: 0.9448 - val_loss: 1.3337 - val_acc: 0.7205\n",
            "Epoch 12/40\n",
            "48000/48000 [==============================] - 21s 443us/step - loss: 0.2810 - acc: 0.9503 - val_loss: 1.2901 - val_acc: 0.7345\n",
            "Epoch 13/40\n",
            "48000/48000 [==============================] - 21s 440us/step - loss: 0.2899 - acc: 0.9510 - val_loss: 1.2040 - val_acc: 0.7570\n",
            "Epoch 14/40\n",
            "48000/48000 [==============================] - 22s 449us/step - loss: 0.2776 - acc: 0.9567 - val_loss: 1.5926 - val_acc: 0.7000\n",
            "Epoch 15/40\n",
            "48000/48000 [==============================] - 21s 438us/step - loss: 0.2772 - acc: 0.9586 - val_loss: 1.3985 - val_acc: 0.7380\n",
            "Epoch 16/40\n",
            "48000/48000 [==============================] - 22s 448us/step - loss: 0.2701 - acc: 0.9630 - val_loss: 1.2415 - val_acc: 0.7720\n",
            "Epoch 17/40\n",
            "48000/48000 [==============================] - 21s 444us/step - loss: 0.2804 - acc: 0.9609 - val_loss: 1.2335 - val_acc: 0.7605\n",
            "Epoch 18/40\n",
            "48000/48000 [==============================] - 21s 444us/step - loss: 0.2728 - acc: 0.9647 - val_loss: 1.3054 - val_acc: 0.7610\n",
            "Epoch 19/40\n",
            "48000/48000 [==============================] - 21s 447us/step - loss: 0.2796 - acc: 0.9643 - val_loss: 1.4379 - val_acc: 0.7555\n",
            "Epoch 20/40\n",
            "48000/48000 [==============================] - 21s 438us/step - loss: 0.2748 - acc: 0.9666 - val_loss: 1.5692 - val_acc: 0.7405\n",
            "Epoch 21/40\n",
            "48000/48000 [==============================] - 22s 448us/step - loss: 0.2776 - acc: 0.9669 - val_loss: 1.5509 - val_acc: 0.7415\n",
            "Epoch 22/40\n",
            "48000/48000 [==============================] - 21s 440us/step - loss: 0.2784 - acc: 0.9680 - val_loss: 1.3369 - val_acc: 0.7655\n",
            "Epoch 23/40\n",
            "48000/48000 [==============================] - 21s 446us/step - loss: 0.2806 - acc: 0.9684 - val_loss: 1.3290 - val_acc: 0.7655\n",
            "Epoch 24/40\n",
            "48000/48000 [==============================] - 21s 443us/step - loss: 0.2781 - acc: 0.9695 - val_loss: 1.4916 - val_acc: 0.7465\n",
            "Epoch 25/40\n",
            "48000/48000 [==============================] - 21s 443us/step - loss: 0.2795 - acc: 0.9705 - val_loss: 1.4292 - val_acc: 0.7520\n",
            "Epoch 26/40\n",
            "48000/48000 [==============================] - 21s 439us/step - loss: 0.2846 - acc: 0.9686 - val_loss: 1.5066 - val_acc: 0.7545\n",
            "Epoch 27/40\n",
            "48000/48000 [==============================] - 21s 442us/step - loss: 0.2713 - acc: 0.9746 - val_loss: 1.5056 - val_acc: 0.7585\n",
            "Epoch 28/40\n",
            "48000/48000 [==============================] - 21s 441us/step - loss: 0.2901 - acc: 0.9681 - val_loss: 1.3522 - val_acc: 0.7780\n",
            "Epoch 29/40\n",
            "48000/48000 [==============================] - 21s 441us/step - loss: 0.2834 - acc: 0.9709 - val_loss: 1.3510 - val_acc: 0.7755\n",
            "Epoch 30/40\n",
            "48000/48000 [==============================] - 21s 439us/step - loss: 0.2719 - acc: 0.9753 - val_loss: 1.4207 - val_acc: 0.7685\n",
            "Epoch 31/40\n",
            "48000/48000 [==============================] - 21s 440us/step - loss: 0.2905 - acc: 0.9690 - val_loss: 1.3351 - val_acc: 0.7770\n",
            "Epoch 32/40\n",
            "48000/48000 [==============================] - 21s 439us/step - loss: 0.2792 - acc: 0.9733 - val_loss: 1.3930 - val_acc: 0.7710\n",
            "Epoch 33/40\n",
            "48000/48000 [==============================] - 21s 443us/step - loss: 0.2750 - acc: 0.9742 - val_loss: 1.4344 - val_acc: 0.7840\n",
            "Epoch 34/40\n",
            "48000/48000 [==============================] - 21s 442us/step - loss: 0.2861 - acc: 0.9714 - val_loss: 1.5755 - val_acc: 0.7490\n",
            "Epoch 35/40\n",
            "48000/48000 [==============================] - 21s 435us/step - loss: 0.2792 - acc: 0.9736 - val_loss: 1.5138 - val_acc: 0.7560\n",
            "Epoch 36/40\n",
            "48000/48000 [==============================] - 21s 432us/step - loss: 0.2760 - acc: 0.9750 - val_loss: 1.4717 - val_acc: 0.7470\n",
            "Epoch 37/40\n",
            "48000/48000 [==============================] - 21s 434us/step - loss: 0.2756 - acc: 0.9757 - val_loss: 1.3637 - val_acc: 0.7870\n",
            "Epoch 38/40\n",
            "48000/48000 [==============================] - 21s 442us/step - loss: 0.2817 - acc: 0.9730 - val_loss: 1.4331 - val_acc: 0.7775\n",
            "Epoch 39/40\n",
            "48000/48000 [==============================] - 21s 438us/step - loss: 0.2769 - acc: 0.9754 - val_loss: 1.6401 - val_acc: 0.7525\n",
            "Epoch 40/40\n",
            "48000/48000 [==============================] - 21s 438us/step - loss: 0.2762 - acc: 0.9754 - val_loss: 1.6384 - val_acc: 0.7445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TNRUlGqDInG5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###4. Add Data Augmentation"
      ]
    },
    {
      "metadata": {
        "id": "hSaXYN7mb4IX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MnrRUBbdIqIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        },
        "outputId": "4292f360-ebe7-45eb-a054-859f618a0525"
      },
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "datagen = ImageDataGenerator(\n",
        "    #rescale=1./255,  #our image is already normalized so we dont need this\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "datagen.fit(train_images_new)\n",
        "\n",
        "history = model.fit_generator(datagen.flow(train_images_norm, train_labels_norm, batch_size=64),\n",
        "                    steps_per_epoch=int(len(train_images_norm) / 64), epochs=epochs,\n",
        "                   verbose=1, validation_data=(val_images_norm, val_labels_norm))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "750/750 [==============================] - 43s 58ms/step - loss: 1.6629 - acc: 0.4140 - val_loss: 1.3757 - val_acc: 0.5225\n",
            "Epoch 2/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 1.3775 - acc: 0.5199 - val_loss: 1.1541 - val_acc: 0.6045\n",
            "Epoch 3/40\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.2584 - acc: 0.5665 - val_loss: 1.2307 - val_acc: 0.5925\n",
            "Epoch 4/40\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.1794 - acc: 0.6007 - val_loss: 1.0863 - val_acc: 0.6360\n",
            "Epoch 5/40\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.1298 - acc: 0.6221 - val_loss: 1.3692 - val_acc: 0.5350\n",
            "Epoch 6/40\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.0876 - acc: 0.6432 - val_loss: 1.0769 - val_acc: 0.6470\n",
            "Epoch 7/40\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.0661 - acc: 0.6509 - val_loss: 1.1228 - val_acc: 0.6455\n",
            "Epoch 8/40\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 1.0321 - acc: 0.6678 - val_loss: 1.3542 - val_acc: 0.5975\n",
            "Epoch 9/40\n",
            "750/750 [==============================] - 42s 56ms/step - loss: 1.0183 - acc: 0.6746 - val_loss: 0.9833 - val_acc: 0.6855\n",
            "Epoch 10/40\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 1.0035 - acc: 0.6838 - val_loss: 1.2292 - val_acc: 0.6270\n",
            "Epoch 11/40\n",
            "750/750 [==============================] - 41s 55ms/step - loss: 0.9821 - acc: 0.6923 - val_loss: 0.9095 - val_acc: 0.7240\n",
            "Epoch 12/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.9826 - acc: 0.6944 - val_loss: 1.0281 - val_acc: 0.6960\n",
            "Epoch 13/40\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.9714 - acc: 0.7006 - val_loss: 1.0812 - val_acc: 0.6840\n",
            "Epoch 14/40\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.9629 - acc: 0.7063 - val_loss: 0.9567 - val_acc: 0.7025\n",
            "Epoch 15/40\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.9497 - acc: 0.7117 - val_loss: 1.0466 - val_acc: 0.6960\n",
            "Epoch 16/40\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.9419 - acc: 0.7138 - val_loss: 1.1588 - val_acc: 0.6745\n",
            "Epoch 17/40\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.9301 - acc: 0.7203 - val_loss: 0.8774 - val_acc: 0.7460\n",
            "Epoch 18/40\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.9222 - acc: 0.7265 - val_loss: 0.8726 - val_acc: 0.7515\n",
            "Epoch 19/40\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.9105 - acc: 0.7295 - val_loss: 0.8518 - val_acc: 0.7545\n",
            "Epoch 20/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.9117 - acc: 0.7309 - val_loss: 1.3093 - val_acc: 0.6380\n",
            "Epoch 21/40\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.9068 - acc: 0.7338 - val_loss: 0.8612 - val_acc: 0.7450\n",
            "Epoch 22/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.9010 - acc: 0.7345 - val_loss: 1.3942 - val_acc: 0.6325\n",
            "Epoch 23/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.8877 - acc: 0.7406 - val_loss: 0.7967 - val_acc: 0.7725\n",
            "Epoch 24/40\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.8941 - acc: 0.7378 - val_loss: 0.8093 - val_acc: 0.7605\n",
            "Epoch 25/40\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.8807 - acc: 0.7430 - val_loss: 0.9238 - val_acc: 0.7330\n",
            "Epoch 26/40\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.8806 - acc: 0.7450 - val_loss: 0.8386 - val_acc: 0.7615\n",
            "Epoch 27/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.8718 - acc: 0.7486 - val_loss: 0.8473 - val_acc: 0.7530\n",
            "Epoch 28/40\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.8734 - acc: 0.7489 - val_loss: 0.8269 - val_acc: 0.7650\n",
            "Epoch 29/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.8642 - acc: 0.7499 - val_loss: 0.9967 - val_acc: 0.7385\n",
            "Epoch 30/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.8615 - acc: 0.7535 - val_loss: 0.8464 - val_acc: 0.7610\n",
            "Epoch 31/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.8602 - acc: 0.7553 - val_loss: 0.9798 - val_acc: 0.7370\n",
            "Epoch 32/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.8576 - acc: 0.7552 - val_loss: 0.8628 - val_acc: 0.7585\n",
            "Epoch 33/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.8581 - acc: 0.7558 - val_loss: 0.8972 - val_acc: 0.7610\n",
            "Epoch 34/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.8540 - acc: 0.7573 - val_loss: 0.8955 - val_acc: 0.7550\n",
            "Epoch 35/40\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.8485 - acc: 0.7605 - val_loss: 0.8352 - val_acc: 0.7755\n",
            "Epoch 36/40\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.8470 - acc: 0.7614 - val_loss: 0.7982 - val_acc: 0.7770\n",
            "Epoch 37/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.8423 - acc: 0.7626 - val_loss: 0.7856 - val_acc: 0.7895\n",
            "Epoch 38/40\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.8435 - acc: 0.7625 - val_loss: 0.8143 - val_acc: 0.7725\n",
            "Epoch 39/40\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.8402 - acc: 0.7634 - val_loss: 0.8923 - val_acc: 0.7620\n",
            "Epoch 40/40\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.8364 - acc: 0.7672 - val_loss: 0.9850 - val_acc: 0.7315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S2NfzPoCo12s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "outputId": "82e9e63b-db57-42c1-82cb-df05680fec5c"
      },
      "cell_type": "code",
      "source": [
        "#print(epochs)\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# training and validation accuracy\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='validation acc')\n",
        "plt.title('training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# training and validation loss\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
        "plt.title('training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPxLsvciWUCZaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUIkEYSGEEEIlEoSFEEIIlfw/zDzMXwtWkjUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_eFIiCzvp7nP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###5. Add dropout"
      ]
    },
    {
      "metadata": {
        "id": "1rXELeG8qeLv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "3a1c116d-9786-403b-e5f3-7d28f21048ea"
      },
      "cell_type": "code",
      "source": [
        "#from keras import regularizers\n",
        "# set up the layers\n",
        "weight_decay = 1e-4\n",
        "model = models.Sequential()\n",
        "#conv layers   \n",
        "#1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', kernel_regularizer= regularizers.l2(weight_decay), input_shape=(32, 32, 3)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "#3\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu',padding = 'same', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "#4\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "#dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-237f9254a4df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dropout' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5DPOguHTsrUw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBThVEL4sr50",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "datagen = ImageDataGenerator(\n",
        "    #rescale=1./255,  #our image is already normalized so we dont need this\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "datagen.fit(train_images_new)\n",
        "\n",
        "history = model.fit_generator(datagen.flow(train_images_norm, train_labels_norm, batch_size=64),\n",
        "                    steps_per_epoch=int(len(train_images_norm) / 64), epochs=epochs,\n",
        "                   verbose=1, validation_data=(val_images_norm, val_labels_norm))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}