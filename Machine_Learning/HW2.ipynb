{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gshah8/UCF/blob/master/Machine_Learning/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5vSpuR2h9REm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# HW 2\n",
        "\n",
        "The goal of this homework is to create a convolutional neural network for the CIFAR10 data set. \n",
        "See [this colab notebook](https://colab.research.google.com/drive/1LZZviWOzvchcXRdZi2IBx3KOpQOzLalf) how to load the CIFAR data in Keras.\n",
        "\n",
        "You should not use any pretrained convnets that come with Keras. You have to create and train your own convnets with Keras from scratch.\n",
        "\n",
        "## Simple hold-out validation\n",
        "\n",
        "Make sure that the data is divided into: \n",
        "\n",
        "- training set (80%)\n",
        "- validation set (20%)\n",
        "- test set. \n",
        "\n",
        "Use the training set to train your neural networks. Evaluate their performance on the validation data set. \n",
        "\n",
        "After trying several different architectures, choose the one that performs\n",
        "best of the validation set. Try at least four different architectures by using data augmentation, using dropout, varying the number of layers, the number of filters, etc.\n",
        "\n",
        "Train this final architecture on the data from the training set and validation set and evaluate its performance on \n",
        "the test set.\n",
        "\n",
        "## k-fold validation\n",
        "\n",
        "Reevaluate your best architecture using k-fold validation with k=5, that is, the size of the validation fold is 20%. Does the accuracy/loss obtain by k-fold validation differ from the accuracy/loss obtain by simple hold-out validation."
      ]
    },
    {
      "metadata": {
        "id": "tGt5GSXu_g9t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading the CIFAR10 data set\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GaciVEq0_dts",
        "colab_type": "code",
        "outputId": "2b3ded9b-ba5a-440a-8cc1-20ba3697c439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 34s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-AYEf3umAHQm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exploring the format of the CIFAR10 data set"
      ]
    },
    {
      "metadata": {
        "id": "p1hNMiPtAIsN",
        "colab_type": "code",
        "outputId": "32b6d6ef-9820-49d2-e047-dbdc01e99dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "J6KJNpLlAtLb",
        "colab_type": "code",
        "outputId": "5e548d2b-3ad4-4837-f648-487665dcd362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_images.ndim"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "8_SDVSLrAx1L",
        "colab_type": "code",
        "outputId": "8d42d8e1-63f7-41f8-d3f5-3d06113ad43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "14iRg_dJA0Iv",
        "colab_type": "code",
        "outputId": "a4816eb4-8449-415c-8e1f-58a685383587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_labels.ndim"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "Mqbp1flDTvGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Using Simple Hold Validation for the models below"
      ]
    },
    {
      "metadata": {
        "id": "ghUwL-nmUZx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8462008f-3bba-4f5f-be72-e4d4855bbeed"
      },
      "cell_type": "code",
      "source": [
        "#divide training data into training and validation data\n",
        "rand_idx = np.random.permutation(len(train_images))\n",
        "val_idx = rand_idx[0:2000]\n",
        "train_idx = rand_idx[2000:]\n",
        "\n",
        "train_images_new, train_labels_new = train_images[train_idx] , train_labels[train_idx]\n",
        "val_images, val_labels = train_images[val_idx] , train_labels[val_idx]\n",
        "\n",
        "#normalize training and validation data\n",
        "train_images_norm = train_images_new/255.0\n",
        "val_images_norm = val_images/255.0\n",
        "\n",
        "#train_images_norm.shape\n",
        "#train_images_norm.shape\n",
        "train_labels_new[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "FbOE5y_-EzOV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Preprocess test data"
      ]
    },
    {
      "metadata": {
        "id": "w4u6Vq_KE6Oe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "98c7fab9-48c3-471f-c8b5-78a4094255d7"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "#train_images_norm = train_images/255\n",
        "test_images_norm = test_images/255.0\n",
        "\n",
        "#one-hot encoding\n",
        "train_labels_norm = to_categorical(train_labels_new)\n",
        "val_labels_norm = to_categorical(val_labels)\n",
        "test_labels_norm = to_categorical(test_labels)\n",
        "\n",
        "train_labels_norm[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "9vynlXErFcqO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Build a basic model (without Data Augmentation and Dropout)"
      ]
    },
    {
      "metadata": {
        "id": "4d7o1oJLFeqm",
        "colab_type": "code",
        "outputId": "6d4f0c15-42d3-4159-ddc3-211a1102975e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# set up the layers\n",
        "\n",
        "model = models.Sequential()\n",
        "#conv layers   \n",
        "#1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#3\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_98 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_84 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_99 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_85 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_100 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_86 (MaxPooling (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 122,570\n",
            "Trainable params: 122,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mXpTCFSKH-0Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Compile the Model"
      ]
    },
    {
      "metadata": {
        "id": "UY6Yl69XH4b4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jDH1M98B_Zb2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Train the Model"
      ]
    },
    {
      "metadata": {
        "id": "ULo_pCDVIJd_",
        "colab_type": "code",
        "outputId": "3815420d-5519-435a-c66c-65cbc25b2e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "cell_type": "code",
      "source": [
        "#epochs = 20\n",
        "#history = model.fit(train_images_norm, \n",
        "#                      train_labels_norm, \n",
        "#                      epochs=epochs,  \n",
        "#                      validation_data=(val_images_norm, val_labels))\n",
        "\n",
        "#epochs = 20\n",
        "#history = model.fit(train_images_norm, \n",
        "#                      train_labels_norm, \n",
        "#                      epochs=epochs,  \n",
        "#                      validation_data=(val_images_norm, val_labels))\n",
        "\n",
        "\n",
        "\n",
        "epochs = 20\n",
        "history = model.fit(train_images_norm, \n",
        "                      train_labels_norm, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=64, \n",
        "                      validation_data=(val_images_norm, val_labels_norm))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 2000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 12s 243us/step - loss: 1.5230 - acc: 0.4483 - val_loss: 1.2299 - val_acc: 0.5475\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 11s 219us/step - loss: 1.1205 - acc: 0.6035 - val_loss: 1.0132 - val_acc: 0.6355\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 10s 218us/step - loss: 0.9532 - acc: 0.6671 - val_loss: 0.9297 - val_acc: 0.6585\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.8555 - acc: 0.7036 - val_loss: 0.9094 - val_acc: 0.6795\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 10s 217us/step - loss: 0.7809 - acc: 0.7288 - val_loss: 0.8670 - val_acc: 0.6995\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 10s 217us/step - loss: 0.7153 - acc: 0.7494 - val_loss: 0.8177 - val_acc: 0.7240\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.6592 - acc: 0.7708 - val_loss: 0.8152 - val_acc: 0.7255\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 10s 216us/step - loss: 0.6175 - acc: 0.7843 - val_loss: 0.8027 - val_acc: 0.7310\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 10s 214us/step - loss: 0.5705 - acc: 0.8013 - val_loss: 0.7943 - val_acc: 0.7380\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 10s 214us/step - loss: 0.5334 - acc: 0.8141 - val_loss: 0.8051 - val_acc: 0.7395\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 10s 216us/step - loss: 0.4956 - acc: 0.8262 - val_loss: 0.8260 - val_acc: 0.7315\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 10s 216us/step - loss: 0.4599 - acc: 0.8393 - val_loss: 0.8562 - val_acc: 0.7425\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 10s 216us/step - loss: 0.4315 - acc: 0.8471 - val_loss: 0.8889 - val_acc: 0.7370\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.3988 - acc: 0.8588 - val_loss: 0.8721 - val_acc: 0.7430\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 10s 216us/step - loss: 0.3696 - acc: 0.8688 - val_loss: 0.8761 - val_acc: 0.7470\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.3438 - acc: 0.8795 - val_loss: 0.9569 - val_acc: 0.7335\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.3213 - acc: 0.8857 - val_loss: 0.9996 - val_acc: 0.7360\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.2892 - acc: 0.8968 - val_loss: 1.0538 - val_acc: 0.7295\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.2703 - acc: 0.9037 - val_loss: 1.0773 - val_acc: 0.7275\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 10s 215us/step - loss: 0.2554 - acc: 0.9094 - val_loss: 1.0919 - val_acc: 0.7405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B-dIySPtN-Gj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can observe that the model is clearly overfitted since the training accuracy is increasing as we increase the number of epochs but the validation accuracy is not increasing.\n",
        "\n",
        "Now, we will try to improve the model by using the four following architectures:\n",
        "1. increasing the number of convolutional layers\n",
        "2. Adding more filters\n",
        "3. Data Augmentation\n",
        "4. Dropout\n",
        "\n",
        "We will add the above mentioned architectures one by one and observe the training and validation accuracy.\n",
        "In the end, as a final check, we will run the model for test data."
      ]
    },
    {
      "metadata": {
        "id": "kHsI-SikNtfQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####1. Increasing the number of convolutional layers"
      ]
    },
    {
      "metadata": {
        "id": "pTnpHLaERnpt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "dd51b4e9-27c0-4bb8-8b80-1d86762a8dec"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# set up the layers\n",
        "\n",
        "model = models.Sequential()\n",
        "#conv layers   \n",
        "#1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#3\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu',padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#4\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_91 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_77 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_78 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_93 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_79 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_94 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_80 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_20 (Flatten)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 307,786\n",
            "Trainable params: 307,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wEx0Pl9CQlCE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T7RPGQ7ZQqcV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1421
        },
        "outputId": "fe2faa7b-a092-4323-d2cf-e888d406d19c"
      },
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "history = model.fit(train_images_norm, \n",
        "                      train_labels_norm, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=64, \n",
        "                      validation_data=(val_images_norm, val_labels_norm))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 2000 samples\n",
            "Epoch 1/40\n",
            "48000/48000 [==============================] - 16s 334us/step - loss: 1.5184 - acc: 0.4419 - val_loss: 1.1870 - val_acc: 0.5580\n",
            "Epoch 2/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 1.0602 - acc: 0.6225 - val_loss: 0.9539 - val_acc: 0.6490\n",
            "Epoch 3/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.8468 - acc: 0.7018 - val_loss: 0.8437 - val_acc: 0.7095\n",
            "Epoch 4/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.7225 - acc: 0.7469 - val_loss: 0.9177 - val_acc: 0.6865\n",
            "Epoch 5/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.6219 - acc: 0.7812 - val_loss: 0.8103 - val_acc: 0.7235\n",
            "Epoch 6/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.5327 - acc: 0.8119 - val_loss: 0.7843 - val_acc: 0.7415\n",
            "Epoch 7/40\n",
            "48000/48000 [==============================] - 14s 301us/step - loss: 0.4543 - acc: 0.8398 - val_loss: 0.7438 - val_acc: 0.7595\n",
            "Epoch 8/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.3872 - acc: 0.8627 - val_loss: 0.7900 - val_acc: 0.7565\n",
            "Epoch 9/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.3271 - acc: 0.8850 - val_loss: 0.8384 - val_acc: 0.7535\n",
            "Epoch 10/40\n",
            "48000/48000 [==============================] - 14s 301us/step - loss: 0.2793 - acc: 0.8997 - val_loss: 0.9169 - val_acc: 0.7495\n",
            "Epoch 11/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.2377 - acc: 0.9135 - val_loss: 1.0212 - val_acc: 0.7500\n",
            "Epoch 12/40\n",
            "48000/48000 [==============================] - 14s 301us/step - loss: 0.2066 - acc: 0.9265 - val_loss: 1.0355 - val_acc: 0.7470\n",
            "Epoch 13/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.1693 - acc: 0.9400 - val_loss: 1.0887 - val_acc: 0.7555\n",
            "Epoch 14/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.1640 - acc: 0.9411 - val_loss: 1.2274 - val_acc: 0.7335\n",
            "Epoch 15/40\n",
            "48000/48000 [==============================] - 14s 301us/step - loss: 0.1354 - acc: 0.9514 - val_loss: 1.2483 - val_acc: 0.7470\n",
            "Epoch 16/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.1371 - acc: 0.9512 - val_loss: 1.3656 - val_acc: 0.7370\n",
            "Epoch 17/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.1260 - acc: 0.9542 - val_loss: 1.3459 - val_acc: 0.7545\n",
            "Epoch 18/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.1181 - acc: 0.9579 - val_loss: 1.3833 - val_acc: 0.7390\n",
            "Epoch 19/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.1101 - acc: 0.9612 - val_loss: 1.5523 - val_acc: 0.7225\n",
            "Epoch 20/40\n",
            "48000/48000 [==============================] - 14s 301us/step - loss: 0.1088 - acc: 0.9608 - val_loss: 1.4369 - val_acc: 0.7470\n",
            "Epoch 21/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.0943 - acc: 0.9662 - val_loss: 1.6102 - val_acc: 0.7400\n",
            "Epoch 22/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.1006 - acc: 0.9654 - val_loss: 1.5217 - val_acc: 0.7485\n",
            "Epoch 23/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.0973 - acc: 0.9664 - val_loss: 1.5881 - val_acc: 0.7380\n",
            "Epoch 24/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.0884 - acc: 0.9697 - val_loss: 1.5520 - val_acc: 0.7450\n",
            "Epoch 25/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0869 - acc: 0.9698 - val_loss: 1.5926 - val_acc: 0.7330\n",
            "Epoch 26/40\n",
            "48000/48000 [==============================] - 14s 297us/step - loss: 0.0806 - acc: 0.9728 - val_loss: 1.6262 - val_acc: 0.7410\n",
            "Epoch 27/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0901 - acc: 0.9687 - val_loss: 1.5559 - val_acc: 0.7530\n",
            "Epoch 28/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.0688 - acc: 0.9764 - val_loss: 1.7931 - val_acc: 0.7405\n",
            "Epoch 29/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.0894 - acc: 0.9696 - val_loss: 1.6769 - val_acc: 0.7480\n",
            "Epoch 30/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0806 - acc: 0.9723 - val_loss: 1.6999 - val_acc: 0.7425\n",
            "Epoch 31/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.0682 - acc: 0.9764 - val_loss: 1.7562 - val_acc: 0.7390\n",
            "Epoch 32/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0735 - acc: 0.9745 - val_loss: 1.8480 - val_acc: 0.7400\n",
            "Epoch 33/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0831 - acc: 0.9715 - val_loss: 1.7513 - val_acc: 0.7425\n",
            "Epoch 34/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.0678 - acc: 0.9773 - val_loss: 1.6725 - val_acc: 0.7435\n",
            "Epoch 35/40\n",
            "48000/48000 [==============================] - 14s 299us/step - loss: 0.0679 - acc: 0.9768 - val_loss: 1.7472 - val_acc: 0.7485\n",
            "Epoch 36/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0669 - acc: 0.9775 - val_loss: 1.7366 - val_acc: 0.7510\n",
            "Epoch 37/40\n",
            "48000/48000 [==============================] - 14s 302us/step - loss: 0.0655 - acc: 0.9783 - val_loss: 1.8600 - val_acc: 0.7305\n",
            "Epoch 38/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0705 - acc: 0.9764 - val_loss: 1.8105 - val_acc: 0.7530\n",
            "Epoch 39/40\n",
            "48000/48000 [==============================] - 14s 298us/step - loss: 0.0700 - acc: 0.9771 - val_loss: 1.7070 - val_acc: 0.7545\n",
            "Epoch 40/40\n",
            "48000/48000 [==============================] - 14s 300us/step - loss: 0.0604 - acc: 0.9799 - val_loss: 1.7302 - val_acc: 0.7475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z0xXI48M5qfA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adding another layer increased the testing accuracy by around 2% (not a significant increase). However, the scale is overfitting has increased even more since the training accuracy is around 98% for the 40th epoch whereas it is just around 75% for validation data.\n",
        "\n",
        "Therefore, now we are going to include regularization, data augmentation and dropout one by one to the existing model with 4 layers in order to see how to validation accuracy improves and overfitting is minimized."
      ]
    },
    {
      "metadata": {
        "id": "U2Nzey546Yh6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Add Regularizer"
      ]
    },
    {
      "metadata": {
        "id": "1aMBqYWq980h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "23855d8e-5a16-4960-c9f0-4cf3db43f05c"
      },
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "# set up the layers\n",
        "weight_decay = 1e-4\n",
        "model = models.Sequential()\n",
        "#conv layers   \n",
        "#1\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding = 'same', kernel_regularizer= regularizers.l2(weight_decay), input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#2\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding = 'same', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#3\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu',padding = 'same', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#4\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding = 'same', kernel_regularizer= regularizers.l2(weight_decay)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "#dense layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_107 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_92 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_108 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_93 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_109 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_94 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_110 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_95 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 307,786\n",
            "Trainable params: 307,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o7voAcZ-_6Mo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xhzyrOQM_6dC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1421
        },
        "outputId": "83076358-f857-4410-e08f-e4a9c6889cc9"
      },
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "history = model.fit(train_images_norm, \n",
        "                      train_labels_norm, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=64, \n",
        "                      validation_data=(val_images_norm, val_labels_norm))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 2000 samples\n",
            "Epoch 1/40\n",
            "48000/48000 [==============================] - 16s 336us/step - loss: 1.5280 - acc: 0.4500 - val_loss: 1.2838 - val_acc: 0.5445\n",
            "Epoch 2/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 1.1128 - acc: 0.6173 - val_loss: 1.0010 - val_acc: 0.6530\n",
            "Epoch 3/40\n",
            "48000/48000 [==============================] - 15s 308us/step - loss: 0.9257 - acc: 0.6899 - val_loss: 0.8848 - val_acc: 0.7070\n",
            "Epoch 4/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.8100 - acc: 0.7372 - val_loss: 0.8429 - val_acc: 0.7310\n",
            "Epoch 5/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.7256 - acc: 0.7685 - val_loss: 0.8397 - val_acc: 0.7220\n",
            "Epoch 6/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.6567 - acc: 0.7932 - val_loss: 0.7882 - val_acc: 0.7525\n",
            "Epoch 7/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.6021 - acc: 0.8151 - val_loss: 0.8284 - val_acc: 0.7530\n",
            "Epoch 8/40\n",
            "48000/48000 [==============================] - 15s 308us/step - loss: 0.5519 - acc: 0.8352 - val_loss: 0.8492 - val_acc: 0.7540\n",
            "Epoch 9/40\n",
            "48000/48000 [==============================] - 15s 305us/step - loss: 0.5036 - acc: 0.8545 - val_loss: 0.8855 - val_acc: 0.7490\n",
            "Epoch 10/40\n",
            "48000/48000 [==============================] - 15s 304us/step - loss: 0.4563 - acc: 0.8737 - val_loss: 1.0073 - val_acc: 0.7360\n",
            "Epoch 11/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.4235 - acc: 0.8883 - val_loss: 0.9329 - val_acc: 0.7530\n",
            "Epoch 12/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.3839 - acc: 0.9025 - val_loss: 1.0544 - val_acc: 0.7525\n",
            "Epoch 13/40\n",
            "48000/48000 [==============================] - 15s 308us/step - loss: 0.3662 - acc: 0.9099 - val_loss: 1.0672 - val_acc: 0.7595\n",
            "Epoch 14/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.3516 - acc: 0.9187 - val_loss: 1.1120 - val_acc: 0.7420\n",
            "Epoch 15/40\n",
            "48000/48000 [==============================] - 15s 305us/step - loss: 0.3375 - acc: 0.9257 - val_loss: 1.2548 - val_acc: 0.7360\n",
            "Epoch 16/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.3227 - acc: 0.9311 - val_loss: 1.2152 - val_acc: 0.7320\n",
            "Epoch 17/40\n",
            "48000/48000 [==============================] - 15s 305us/step - loss: 0.3112 - acc: 0.9372 - val_loss: 1.2858 - val_acc: 0.7355\n",
            "Epoch 18/40\n",
            "48000/48000 [==============================] - 15s 308us/step - loss: 0.3076 - acc: 0.9415 - val_loss: 1.4021 - val_acc: 0.7280\n",
            "Epoch 19/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2952 - acc: 0.9460 - val_loss: 1.3860 - val_acc: 0.7385\n",
            "Epoch 20/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.3019 - acc: 0.9449 - val_loss: 1.4411 - val_acc: 0.7490\n",
            "Epoch 21/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2964 - acc: 0.9484 - val_loss: 1.4191 - val_acc: 0.7400\n",
            "Epoch 22/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2831 - acc: 0.9539 - val_loss: 1.4541 - val_acc: 0.7415\n",
            "Epoch 23/40\n",
            "48000/48000 [==============================] - 15s 308us/step - loss: 0.2880 - acc: 0.9537 - val_loss: 1.5027 - val_acc: 0.7435\n",
            "Epoch 24/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2896 - acc: 0.9536 - val_loss: 1.4449 - val_acc: 0.7430\n",
            "Epoch 25/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2800 - acc: 0.9582 - val_loss: 1.4841 - val_acc: 0.7535\n",
            "Epoch 26/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2849 - acc: 0.9569 - val_loss: 1.4062 - val_acc: 0.7525\n",
            "Epoch 27/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2843 - acc: 0.9584 - val_loss: 1.5356 - val_acc: 0.7455\n",
            "Epoch 28/40\n",
            "48000/48000 [==============================] - 15s 311us/step - loss: 0.2797 - acc: 0.9601 - val_loss: 1.4867 - val_acc: 0.7385\n",
            "Epoch 29/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2830 - acc: 0.9610 - val_loss: 1.5011 - val_acc: 0.7500\n",
            "Epoch 30/40\n",
            "48000/48000 [==============================] - 15s 305us/step - loss: 0.2806 - acc: 0.9623 - val_loss: 1.5158 - val_acc: 0.7480\n",
            "Epoch 31/40\n",
            "48000/48000 [==============================] - 15s 305us/step - loss: 0.2825 - acc: 0.9611 - val_loss: 1.5289 - val_acc: 0.7445\n",
            "Epoch 32/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2733 - acc: 0.9649 - val_loss: 1.5470 - val_acc: 0.7415\n",
            "Epoch 33/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2846 - acc: 0.9619 - val_loss: 1.5867 - val_acc: 0.7540\n",
            "Epoch 34/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2756 - acc: 0.9641 - val_loss: 1.5374 - val_acc: 0.7465\n",
            "Epoch 35/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2815 - acc: 0.9640 - val_loss: 1.5772 - val_acc: 0.7520\n",
            "Epoch 36/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2673 - acc: 0.9680 - val_loss: 1.6316 - val_acc: 0.7475\n",
            "Epoch 37/40\n",
            "48000/48000 [==============================] - 15s 305us/step - loss: 0.2708 - acc: 0.9676 - val_loss: 1.5794 - val_acc: 0.7460\n",
            "Epoch 38/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2783 - acc: 0.9645 - val_loss: 1.6266 - val_acc: 0.7365\n",
            "Epoch 39/40\n",
            "48000/48000 [==============================] - 15s 307us/step - loss: 0.2795 - acc: 0.9653 - val_loss: 1.5929 - val_acc: 0.7405\n",
            "Epoch 40/40\n",
            "48000/48000 [==============================] - 15s 306us/step - loss: 0.2699 - acc: 0.9681 - val_loss: 1.6162 - val_acc: 0.7450\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}