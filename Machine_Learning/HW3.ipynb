{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gshah8/UCF/blob/master/Machine_Learning/HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "IOCUFpgzSX9E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# HW 3\n",
        "\n",
        "The goal of this homework is to learn how to leverage pretrained convnets and to use some visualization techniques.\n",
        "You will work with the data set *cats vs dogs* and use the pretrained convnet VGG19.\n",
        "\n",
        "Experiment with different classifiers, trying to maximize the validation accuracy. You only need to show one classifier.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UNKyKTKQrcft",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Download the data"
      ]
    },
    {
      "metadata": {
        "id": "5Ja05m5_rmad",
        "colab_type": "code",
        "outputId": "65ebacaa-4a81-4dbf-9322-c639ab80ed75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-16 19:56:48--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "\r          /tmp/cats   0%[                    ]       0  --.-KB/s               \r         /tmp/cats_  57%[==========>         ]  37.36M   187MB/s               \r/tmp/cats_and_dogs_ 100%[===================>]  65.43M   232MB/s    in 0.3s    \n",
            "\n",
            "2019-04-16 19:56:48 (232 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SnVT7SRRrsMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ihtWwyLtnMI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "\n",
        "# Directory with our training dog pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# Directory with our validation cat pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "\n",
        "# Directory with our validation dog pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9sSG0XTOvfL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Load the convolutional base"
      ]
    },
    {
      "metadata": {
        "id": "ZSpcJo6Dvisb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e69b2f5b-2643-4563-f62e-d4f4082db7ad"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "\n",
        "conv_base = VGG19(\n",
        "    weights='imagenet', \n",
        "    include_top=False, \n",
        "    input_shape=(150, 150, 3))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m43nvNBaS2Vk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 1\n",
        "\n",
        "Do feature extraction with data augmentation."
      ]
    },
    {
      "metadata": {
        "id": "FEtiCScJwBK0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to freeze the convolutional base for Problem 1"
      ]
    },
    {
      "metadata": {
        "id": "c3q-wHgITGfM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-vXw3eEtS6DL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 2\n",
        "\n",
        "Do fine-tuning with data augmentation. "
      ]
    },
    {
      "metadata": {
        "id": "H4BX1BmYS6RC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 3\n",
        "\n",
        "Visualize heatmaps of class activation for the the model obtained in Problem 2.\n"
      ]
    },
    {
      "metadata": {
        "id": "wZWSm1HKS6dc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problem 4\n",
        "\n",
        "Build an activation model that takes as input an image and produces as output the activation of the last conv layer of the model obtained in Problem 2. Using this activation model obtain the corresponding activations for the validation images. Apply t-SNE visualization to these activations to see how well the convnet separates cats from dogs."
      ]
    },
    {
      "metadata": {
        "id": "2v5ZtmHOSZCF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}